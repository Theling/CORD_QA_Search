{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCU1sltzhqJX"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBpm_qG0WqXX"
   },
   "source": [
    "  As everyone unfortunately knows, COVID-19 has brought the world to a standstill and is the worst pandemic in a century. Because of this, the world health community has devoted an unprecedented amount of resources towards the study, containment, and hopefully the eradication of this disease. However, this also means that an unprecedented amount of data has been produced, much more than researchers and journalists can sort through by hand. Thus, this contest was started by Kaggle to help develop new methods of sorting through the massive amount of papers being written on the subject. Our contribution is to make major improvements on the method developed by \"dirktheeng\" in their “Anserini+BERT-SQuAD for Semantic Corpus Search” notebook. The link to their notebook can be found here: https://www.kaggle.com/dirktheeng\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BUhsK1XhqJd"
   },
   "source": [
    "## Methodology\n",
    "\n",
    "Our methodology is very similar to the one used in the original notebook. The basic idea is to use the BERT model to perform basic question and answer tasks, i.e. the user can ask the model a question, and it will return what it thinks the best answer is from a database. In the case of the original notebook, this model was used to scan through numerous paper abstracts to find which abstracts best answer the question. To do this, the model would take in a question plus candidate abstract and output a start index, end index, and its confidence value. The start index is where the most relevant part of the text starts, the end index is where it ends, and the confidence value is how sure it is that’s the right answer. The model then does this for the rest of the abstracts, ranks them based on confidence values, and returns the answer it’s most confident of, along with the paper that it comes from. This is a perfectly fine model, however, there were a few key improvements that we were able to make.\n",
    "\n",
    "First, we extended the model to search the entire paper, not just the abstract. The BERT model is only able to handle text shorter than 512 words. When factoring in the length of the question statement, this means that the original model could only handle chunks of text shorter than 500 words. Since abstracts are always shorter than that, the length constraints weren’t an issue for the original model. However, there is a lot of potentially useful information in the body of these papers, so it would better if the model could scan this as well. To do this, we simply broke up longer text into chucks less than 500 words, and ran each smaller chunk through the model separately. Thus, we were able to find which part of the paper was most relevant and return it. Also, this requires much more data than the original model’s database, which only included the abstracts. So, we added in a way to upload the body text, match it to the right abstract, merge the two, and pass the full text on to the model. This allows our improved model to handle much more data.\n",
    "\n",
    "Second, there was a major bug in the original model where it could return nonsensical index ranges where the start index came after the end index. For example, if the model returns a range of [26,13], it’s impossible to reconstruct the answer from that. We came up with a rather ingenious solution to this problem. If the model returns a range such as [26,13], our new model fix that by breaking the original text chunk into two parts, say [0,13] and [26,n-1] (n is the length of the original text chunk). Then, it will find two new potential answer ranges, say [7,13] and [26,31], and return the one it’s more confident of. Thus, our new model fixes this bug and is more reliable. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EChlz0IzhqJn"
   },
   "source": [
    "## Setup Envirnment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6O5y4EoHh7Bn"
   },
   "source": [
    "Note, this is the line of code you need to run when using Linux (Ubuntu 16). On other platforms, this may be different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IHhUCGFUh5Rn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/jdk-11.0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "colab_type": "code",
    "id": "k8T9L1I9igH6",
    "outputId": "1e3afd46-e206-4450-9414-06a15257492d"
   },
   "outputs": [],
   "source": [
    "!pip install pyserini\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjDbOsNHhqIQ"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import pandas as pd\n",
    "from pyserini.search import pysearch\n",
    "import numpy as np\n",
    "from BERT_func import BERT_SQUAD_QA\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEn87vSqUpVW"
   },
   "source": [
    "Note: You will need to load in a file called \"database.json\" into your workspace for this notebook to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2YESbCtuZjv"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget -O lucene.tar.gz https://www.dropbox.com/s/d6v9fensyi7q3gb/lucene-index-covid-2020-04-03.tar.gz?dl=0\n",
    "!tar xvfz lucene.tar.gz\n",
    "minDate = '2020/04/02'\n",
    "luceneDir = 'lucene-index-covid-2020-04-03/'\n",
    "torch_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaTyf40WhqJp"
   },
   "outputs": [],
   "source": [
    "#You can just run this cell if you ran the previous cell or already have 'lucene-index-covid-2020-04-03/' set up\n",
    "torch_device = 'cpu'\n",
    "minDate = '2020/04/02'\n",
    "luceneDir = 'lucene-index-covid-2020-04-03/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "W8AUYQMThqJ3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_MODEL = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "QA_TOKENIZER = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "QA_MODEL.to(torch_device)\n",
    "QA_MODEL.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsjV9_CvlsEL"
   },
   "source": [
    "Note, we need to actually get the data first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1wY9OHbIfqJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./content/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./content/ # There is no need to run this if using google Colab, since the content folder should already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "R2TqHpUqlVgN",
    "outputId": "16d22473-23b6-464c-830e-2b1a6cc3087b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./content/kaggle/’: File exists\n",
      "mkdir: cannot create directory ‘./content/kaggle/working/’: File exists\n",
      "mkdir: cannot create directory ‘./content/kaggle/working/sentence_wise_email/’: File exists\n",
      "mkdir: cannot create directory ‘./content/kaggle/working/sentence_wise_email/module/’: File exists\n",
      "mkdir: cannot create directory ‘./content/kaggle/working/sentence_wise_email/module/module_useT’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "tar: /content/kaggle/working//sentence_wise_email/module/module_useT: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "  0  745M    0  108k    0     0   109k      0  1:56:34 --:--:--  1:56:34  109k\n",
      "curl: (23) Failed writing body (968 != 1396)\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./content/kaggle/\n",
    "!mkdir ./content/kaggle/working/\n",
    "!mkdir ./content/kaggle/working/sentence_wise_email/\n",
    "!mkdir ./content/kaggle/working/sentence_wise_email/module/\n",
    "!mkdir ./content/kaggle/working/sentence_wise_email/module/module_useT\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "!curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | tar -zxvC /content/kaggle/working//sentence_wise_email/module/module_useT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjqqZffmlS8C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./content/result/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./content/result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHYlnTYxhqJ_"
   },
   "source": [
    "## Embbeding Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "svBfNRXWhqKA",
    "outputId": "2884c47d-06e8-41b7-ee54-8c38e4dca51d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "def embed_useT(module):\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.compat.v1.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.compat.v1.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})\n",
    "embed_fn = embed_useT('./content/kaggle/working/sentence_wise_email/module/module_useT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoC4JSL7hqKI"
   },
   "source": [
    "## Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5ksYc3-hqKJ"
   },
   "outputs": [],
   "source": [
    "workingPath = './content/kaggle/working'\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#from summarizer import Summarizer\n",
    "#summarizerModel = Summarizer()\n",
    "def displayResults(hit_dictionary, answers, question, abst):\n",
    "    \n",
    "    question_HTML = '<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: '+question+'</div>'\n",
    "    #all_HTML_txt = question_HTML\n",
    "    confidence = list(answers.keys())\n",
    "    confidence.sort(reverse=True)\n",
    "    \n",
    "    confidence = list(answers.keys())\n",
    "    confidence.sort(reverse=True)\n",
    "    \n",
    "\n",
    "    for c in confidence:\n",
    "        if c>0 and c <= 1 and len(answers[c]['answer']) != 0:\n",
    "            rowData = []\n",
    "#             idx = answers[c]['idx']\n",
    "#             title = hit_dictionary[idx]['title']\n",
    "#             authors = hit_dictionary[idx]['authors'] + ' et al.'\n",
    "\n",
    "            \n",
    "            full_abs = answers[c]['abstract_bert']\n",
    "            bert_ans = answers[c]['answer']\n",
    "            #print(full_abs)\n",
    "            \n",
    "            \n",
    "            split_abs = full_abs.split(bert_ans)\n",
    "            sentance_beginning = split_abs[0][split_abs[0].rfind('.')+1:]\n",
    "            #print (sentance_beginning)\n",
    "            if len(split_abs) == 1:\n",
    "                sentance_end_pos = len(full_abs)\n",
    "                sentance_end =''\n",
    "            else:\n",
    "                sentance_end_pos = split_abs[1].find('. ')+1\n",
    "                if sentance_end_pos == 0:\n",
    "                    sentance_end = split_abs[1]\n",
    "                else:\n",
    "                    sentance_end = split_abs[1][:sentance_end_pos]\n",
    "                \n",
    "            #sentance_full = sentance_beginning + bert_ans+ sentance_end\n",
    "            answers[c]['full_answer'] = sentance_beginning+bert_ans+sentance_end\n",
    "            answers[c]['sentence_beginning'] = sentance_beginning\n",
    "            answers[c]['sentence_end'] = sentance_end\n",
    "            #answers[c]['title'] = title\n",
    "            #answers[c]['doi'] = doi\n",
    "        else:\n",
    "            answers.pop(c)\n",
    "            \n",
    "    #print(list(answers.keys()))\n",
    "    \n",
    "    ## now rerank based on semantic similarity of the answers to the question\n",
    "    cList = list(answers.keys())\n",
    "    allAnswers = [answers[c]['full_answer'] for c in cList]\n",
    "    #print('all:', allAnswers)\n",
    "    \n",
    "    messages = [question]+allAnswers\n",
    "    \n",
    "    encoding_matrix = embed_fn(messages)\n",
    "    similarity_matrix = np.inner(encoding_matrix, encoding_matrix)\n",
    "    rankings = similarity_matrix[1:,0]\n",
    "    \n",
    "    for i,c in enumerate(cList):\n",
    "        answers[rankings[i]] = answers.pop(c)\n",
    "    \n",
    "    ## now form pandas dv\n",
    "    confidence = list(answers.keys())\n",
    "    confidence.sort(reverse=True)\n",
    "    pandasData = []\n",
    "    ranked_aswers = []\n",
    "    for c in confidence:\n",
    "        rowData=[]\n",
    "        title = answers[c]['title']\n",
    "        author = answers[c]['author']\n",
    "        doi = None\n",
    "        #idx = answers[c]['idx']\n",
    "        #rowData += [idx]            \n",
    "        sentance_html = '<div>' +answers[c]['sentence_beginning'] + \" <font color='red'>\"+answers[c]['answer']+\"</font> \"+answers[c]['sentence_end']+'</div>'\n",
    "        #print (sentance_html)\n",
    "        rowData += [title,author, sentance_html, c]\n",
    "        pandasData.append(rowData)\n",
    "        ranked_aswers.append(' '.join([answers[c]['full_answer']]))\n",
    "    \n",
    "    pdata2 = pandasData\n",
    "        \n",
    "    \n",
    "    display(HTML(question_HTML))\n",
    "    \n",
    "    df = pd.DataFrame(pdata2, columns = ['Title','Authors', 'BERT-SQuAD Answer with Highlights', 'Confidence'])\n",
    "    tit = '_'.join(question.split(' '))\n",
    "    if abst:\n",
    "        df.to_csv('./result/Abs+' + tit + '.csv')\n",
    "        print('Search with only Abstract')\n",
    "    else:\n",
    "        df.to_csv('./result/Full+' + tit + '.csv')\n",
    "        print ('Search with full paper')\n",
    "        \n",
    "    display(HTML(df.to_html(render_links=True, escape=False)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process\n",
    "* Search papers with Anserini\n",
    "* Match papers from anserini with Kaggle dataset\n",
    "* Use BERT to predict answer\n",
    "* Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPHTEPNphqKP"
   },
   "outputs": [],
   "source": [
    "def Display_all(query, keywords, abst):\n",
    "    \n",
    "    #search with luceneDir database by anserini\n",
    "    searcher = pysearch.SimpleSearcher(luceneDir)\n",
    "    hits = searcher.search(query + '. ' + keywords)\n",
    "    n_hits = len(hits)\n",
    "    #finds the most relvent docs from the database\n",
    "    \n",
    "    #get database by ourselves, this is what database.json does\n",
    "    with open('database.json', 'r') as fp:\n",
    "        database = json.loads(fp.read())\n",
    "        \n",
    "    ID = []\n",
    "    for i in range(0, n_hits):\n",
    "        doc_json = json.loads(hits[i].raw)\n",
    "        try:\n",
    "            ID.append(doc_json['paper_id'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    database_df = pd.DataFrame(database).T\n",
    "    \n",
    "    database_df['abs_text'] = database_df.abstract+ database_df['full-text']\n",
    "    #this part adds in the full text\n",
    "\n",
    "    \n",
    "    #match with own database, this compares the two results\n",
    "    ID_real = []\n",
    "    for Id in ID:\n",
    "        if abst:\n",
    "            if Id in database and ~database_df.loc[Id].isna().abstract:\n",
    "                #print(database_df.loc[Id].isna().abstract)\n",
    "                ID_real.append(Id)\n",
    "        else:\n",
    "            if Id in database and ~database_df.loc[Id].isna()['abs_text']:\n",
    "                ID_real.append(Id)\n",
    "            \n",
    "    #print (ID_real)\n",
    "    \n",
    "    hit_dictionary = database_df.loc[ID_real].to_dict('index')\n",
    "    \n",
    "    QA_model = BERT_SQUAD_QA(QA_TOKENIZER, QA_MODEL)\n",
    "    ans = QA_model.search_abstracts(hit_dictionary, query, abst)\n",
    "    \n",
    "    displayResults(hit_dictionary, ans, query, abst)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wM-4p6iIhqKU"
   },
   "outputs": [],
   "source": [
    "all_topics=[\n",
    "    'What is known about transmission, incubation, and environmental stability?',\n",
    "    'What do we know about COVID-19 risk factors?',\n",
    "    'What do we know about virus genetics, origin, and evolution?',\n",
    "    'What do we know about vaccines and therapeutics?',\n",
    "    'What do we know about non-pharmaceutical interventions?',\n",
    "    'What has been published about medical care?',\n",
    "    'What do we know about diagnostics and surveillance?',\n",
    "    'What has been published about information sharing and inter-sectoral collaboration?',\n",
    "    'What has been published about ethical and social science considerations?'\n",
    "]\n",
    "topic_area = {}\n",
    "\n",
    "#0\n",
    "#What is known about transmission, incubation, and environmental stability?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "pm_kw_list = []\n",
    "question_list.append(\"What is known about transmission, incubation, and environmental stability\")\n",
    "kw_list.append(\"2019-nCoV, COVID-19, coronavirus, person to person,touch,temperature, human to human, humidity, interpersonal contact,, transmission, shedding\")\n",
    "\n",
    "\n",
    "\n",
    "topic_area['What is known about transmission, incubation, and environmental stability?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "\n",
    "\n",
    "#1\n",
    "#What do we know about COVID-19 risk factors?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "\n",
    "question_list.append(\"What risk factors contribute to the severity of 2019-nCoV\")\n",
    "kw_list.append(\"2019-nCoV, COVID-19, coronavirus, novel coronavirus, susceptible, neonates, pregnant, socio-economic, behavioral, age, elderly, young, old, children\")\n",
    "\n",
    "\n",
    "topic_area['What do we know about COVID-19 risk factors?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "\n",
    "#2\n",
    "#What do we know about virus genetics, origin, and evolution?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "\n",
    "\n",
    "question_list.append(\"What animal did 2019-nCoV come from\")\n",
    "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, coronavirus, novel coronavirus, animals, zoonotic, farm, spillover, animal to human, bats, snakes, exotic animals\")\n",
    "\n",
    "\n",
    "topic_area['What do we know about virus genetics, origin, and evolution?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "#3\n",
    "#What do we know about vaccines and therapeutics?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "pm_kw_list = []\n",
    "question_list.append(\"What drugs or therapies or antiviral are being investigated and recommended\")\n",
    "kw_list.append(\"2019-nCoV,  COVID-19, coronavirus, novel coronavirus, drug, antiviral, testing, clinical trial, study\")\n",
    "\n",
    "\n",
    "topic_area['What do we know about vaccines and therapeutics?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "\n",
    "#4\n",
    "#What do we know about non-pharmaceutical interventions?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "question_list.append(\"Which non-pharmaceutical interventions limit tramsission\")\n",
    "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, non-pharmaceutical interventions, npi\")\n",
    "\n",
    "\n",
    "topic_area['What do we know about non-pharmaceutical interventions?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "#5\n",
    "#What has been published about medical care?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "\n",
    "\n",
    "question_list.append(\"What adjunctive or supportive methods can help patients\")\n",
    "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, adjunctive, supportive, extracorporeal membrane oxygenation, ecmo\")\n",
    "\n",
    "\n",
    "topic_area['What has been published about medical care?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "#6\n",
    "#What do we know about diagnostics and surveillance?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "question_list.append(\"What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV\")\n",
    "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, coronavirus, novel coronavirus, diagnosis, tools, detetion, testing, throughput\")\n",
    "\n",
    "topic_area['What do we know about diagnostics and surveillance?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "\n",
    "\n",
    "#7\n",
    "#What has been published about information sharing and inter-sectoral collaboration?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "\n",
    "question_list.append('What collaborations are happening within the research community')\n",
    "kw_list.append('inter-sectorial, international, collaboration, global, coronavirus, novel coronavirus, sharing')\n",
    "\n",
    "\n",
    "topic_area['What has been published about information sharing and inter-sectoral collaboration?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "\n",
    "#8\n",
    "#What has been published about ethical and social science considerations?\n",
    "question_list = []\n",
    "kw_list = []\n",
    "\n",
    "\n",
    "question_list.append(\"What are the major ethical issues related pandemic outbreaks\")\n",
    "kw_list.append(\"ehtics, pandemic, caregivers, health care workers, social media\")\n",
    "\n",
    "\n",
    "topic_area['What has been published about ethical and social science considerations?'] = list(zip(question_list,kw_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "colab_type": "code",
    "id": "x0Gkj2vEhqKg",
    "outputId": "4fe847d2-368a-4c20-bc7a-6fa3445c3a0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What is known about transmission, incubation, and environmental stability</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isolation and identification of human coronavirus 229E from frequently touched environmental surfaces of a university classroom that is cleaned daily</td>\n",
       "      <td>Tania Bonny</td>\n",
       "      <td><div> our findings reinforce the notion that contact transmission may be possible for this virus <font color='red'>cov-229e is relatively stable in the environment. our findings reinforce the notion that contact transmission may be possible for this virus.</font> </div></td>\n",
       "      <td>0.637799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What is known about transmission, incubation, and environmental stability</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isolation and identification of human coronavirus 229E from frequently touched environmental surfaces of a university classroom that is cleaned daily</td>\n",
       "      <td>Tania Bonny</td>\n",
       "      <td><div>  <font color='red'>cov-229e can remain infectious on environmental surfaces, and potentially poses a biohazard by contact transmission</font> </div></td>\n",
       "      <td>0.361994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[0]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "sYrWYjRThqKk",
    "outputId": "8df7c592-d077-4812-ab48-76a0928de469"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What risk factors contribute to the severity of 2019-nCoV</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutrophil-to-Lymphocyte Ratio Predicts Severe Illness Patients with 2019 Novel Coronavirus in the Early Stage</td>\n",
       "      <td>Jingyuan Liu</td>\n",
       "      <td><div> we aimed to select the most useful  <font color='red'>prognostic factor</font>  for severe illness incidence</div></td>\n",
       "      <td>0.505464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Risks of Novel Coronavirus Disease (COVID-19) in Preg- nancy; a Narrative Review</td>\n",
       "      <td>Latif Panahi</td>\n",
       "      <td><div>introduction : the outbreak of the new coronavirus in china in december 2019 and subsequently in various countries around the world has raised concerns about the possibility of  <font color='red'>vertical transmission of the virus from mother to fetus</font> </div></td>\n",
       "      <td>0.339814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3501 > 512). Running this sequence through the model will result in indexing errors\n",
      " 50%|█████     | 1/2 [00:20<00:20, 20.14s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2447 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 2/2 [00:34<00:00, 17.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What risk factors contribute to the severity of 2019-nCoV</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutrophil-to-Lymphocyte Ratio Predicts Severe Illness Patients with 2019 Novel Coronavirus in the Early Stage</td>\n",
       "      <td>Jingyuan Liu</td>\n",
       "      <td><div> the author (s) declare (s) that there is no conflict of interest regarding the publication of this paper <font color='red'>early identification of risk factors for severe illness facilitated appropriate supportive care and promptly access to the intensive care unit (icu) if necessary</font> </div></td>\n",
       "      <td>0.384382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Risks of Novel Coronavirus Disease (COVID-19) in Preg- nancy; a Narrative Review</td>\n",
       "      <td>Latif Panahi</td>\n",
       "      <td><div> there is no conflict of interest <font color='red'>vertical transmission of the virus from mother to fetus</font> </div></td>\n",
       "      <td>0.365697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[1]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klTTFjdbhqKw",
    "outputId": "1c35f9f6-5e44-409b-acd9-a343016eecd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.20it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What animal did 2019-nCoV come from</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outbreak 2019-nCoV (Wuhan virus), a novel Coronavirus: human-to-human transmission, travel-related cases, and vaccine readiness</td>\n",
       "      <td>Robyn Ralph</td>\n",
       "      <td><div> with a seemingly comparable chain of events as the origin of sars-cov, the initial infections with 2019-ncov appears to be linked to contact with animals in  <font color='red'>wet markets</font> .</div></td>\n",
       "      <td>0.423478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNA based mNGS approach identifies a novel human coronavirus from two individual pneumonia cases in 2019 Wuhan outbreak</td>\n",
       "      <td>Liangjun Chen</td>\n",
       "      <td><div> phylogenetic analysis indicates that 2019-ncov is close to coronaviruses (covs) circulating in rhinolophus ( <font color='red'>horseshoe bats</font> ), such as 98.</div></td>\n",
       "      <td>0.404560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consensus statement The species Severe acute respiratory syndrome- related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2 Coronaviridae Study Group of the International Committee on Taxonomy of Viruses*</td>\n",
       "      <td>Info missed</td>\n",
       "      <td><div> based on phylogeny, taxonomy and established practice, the csg recognizes this virus as forming a sister clade to the prototype human and  <font color='red'>bat</font>  severe acute respiratory syndrome corona</div></td>\n",
       "      <td>0.380103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Ping Liu</td>\n",
       "      <td><div>the outbreak of 2019-ncov pneumonia in the city of wuhan, china has resulted in more than 70,000 laboratory confirmed cases, and recent studies showed that 2019-ncov (sars-cov-2) could be of  <font color='red'>bat</font>  origin but involve other potential intermediate hosts.</div></td>\n",
       "      <td>0.327245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerging novel coronavirus (2019-nCoV)-current scenario, evolutionary perspective based on genome analysis and recent developments</td>\n",
       "      <td>Yashpal Singh Malik</td>\n",
       "      <td><div>coronaviruses are the well-known cause of severe respiratory, enteric and systemic infections in a wide range of hosts including man,  <font color='red'>mammals, fish, and avian</font> </div></td>\n",
       "      <td>0.280161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding</td>\n",
       "      <td>Roujian Lu</td>\n",
       "      <td><div> as of jan 26,2020, more than 2000 cases of 2019-ncov infection have been confirmed, most of which involved people living in or visiting wuhan, and  <font color='red'>human</font> -to-</div></td>\n",
       "      <td>0.142267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (4051 > 512). Running this sequence through the model will result in indexing errors\n",
      " 17%|█▋        | 1/6 [00:23<01:55, 23.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6652 > 512). Running this sequence through the model will result in indexing errors\n",
      " 33%|███▎      | 2/6 [01:00<01:49, 27.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (4463 > 512). Running this sequence through the model will result in indexing errors\n",
      " 50%|█████     | 3/6 [01:25<01:20, 26.81s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (8267 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 4/6 [02:12<01:05, 32.80s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3672 > 512). Running this sequence through the model will result in indexing errors\n",
      " 83%|████████▎ | 5/6 [02:33<00:29, 29.20s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6208 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 6/6 [03:08<00:00, 31.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What animal did 2019-nCoV come from</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Ping Liu</td>\n",
       "      <td><div> / <font color='red'>bat</font> </div></td>\n",
       "      <td>0.358401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consensus statement The species Severe acute respiratory syndrome- related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2 Coronaviridae Study Group of the International Committee on Taxonomy of Viruses*</td>\n",
       "      <td>Info missed</td>\n",
       "      <td><div> with this change in place, the csg is resolved to address the existing significant overlap between virus and species names that complicates the appreciation and use of the species concept in its application to coronaviruses <font color='red'>bats</font> </div></td>\n",
       "      <td>0.344850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outbreak 2019-nCoV (Wuhan virus), a novel Coronavirus: human-to-human transmission, travel-related cases, and vaccine readiness</td>\n",
       "      <td>Robyn Ralph</td>\n",
       "      <td><div> 1), were obtained from  <font color='red'>genbank</font> .</div></td>\n",
       "      <td>0.324046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding</td>\n",
       "      <td>Roujian Lu</td>\n",
       "      <td><div> hence,  <font color='red'>bat</font> -sl-covzc45 and </div></td>\n",
       "      <td>0.236836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNA based mNGS approach identifies a novel human coronavirus from two individual pneumonia cases in 2019 Wuhan outbreak</td>\n",
       "      <td>Liangjun Chen</td>\n",
       "      <td><div> no potential conflict of interest was reported by the author (s) <font color='red'>horseshoe bats</font> </div></td>\n",
       "      <td>0.204998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emerging novel coronavirus (2019-nCoV)-current scenario, evolutionary perspective based on genome analysis and recent developments</td>\n",
       "      <td>Yashpal Singh Malik</td>\n",
       "      <td><div> this could provide clues for discovering effective therapeutic regimens and vaccine testing <font color='red'>bats</font> </div></td>\n",
       "      <td>0.127313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[2]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "AWDoGHCehqK1",
    "outputId": "f53b3d9c-91f4-4c0e-a66c-fe37e2aaf291"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What drugs or therapies or antiviral are being investigated and recommended</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review</td>\n",
       "      <td>Junxiong Pang</td>\n",
       "      <td><div> however, there are currently  <font color='red'>no effective specific antivirals or drug combinations</font>  supported by high-level evidence</div></td>\n",
       "      <td>0.785457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A brief review of antiviral drugs evaluated in registered clinical trials for COVID-19</td>\n",
       "      <td>Drifa Belhadi</td>\n",
       "      <td><div>although a number of  <font color='red'>antiviral</font>  agents have been evaluated for coronaviruses there are no approved drugs available.</div></td>\n",
       "      <td>0.764765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effectiveness and safety of antiviral or antibody treatments for coronavirus A rapid review Prepared for Public Health Agency of Canada</td>\n",
       "      <td>Patricia Rios</td>\n",
       "      <td><div>,  <font color='red'>antivirals / antibodies</font> ) to address the current outbreak of a novel coronavirus methods : comprehensive literature searches were developed by an experienced librarian for medline, embase, the cochrane library, and biorxiv.</div></td>\n",
       "      <td>0.635862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3967 > 512). Running this sequence through the model will result in indexing errors\n",
      " 33%|███▎      | 1/3 [00:22<00:45, 22.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (5665 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 2/3 [00:54<00:25, 25.53s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (7817 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 3/3 [01:38<00:00, 32.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What drugs or therapies or antiviral are being investigated and recommended</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effectiveness and safety of antiviral or antibody treatments for coronavirus A rapid review Prepared for Public Health Agency of Canada</td>\n",
       "      <td>Patricia Rios</td>\n",
       "      <td><div> is the (which was not peer-reviewed) the copyright holder for this preprint a protocol for a multi-centre, double blinded, randomised, placebo-controlled trial on the efficacy and safety of lopinavir / ritonavir plus ribavirin in the treatment of severe acute respiratory syndrome recovery from severe novel coronavirus infection mers unavailable ribavirin and interferon-alpha2b as primary and preventive treatment for middle east respiratory syndrome coronavirus : a preliminary report of two <font color='red'>antiviral medications</font> </div></td>\n",
       "      <td>0.538424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review</td>\n",
       "      <td>Junxiong Pang</td>\n",
       "      <td><div> com / xxx / s1, table s1 : example of full search strategy in pubmed, table s2 : google search : 2019-ncov diagnostics, table s3 : summary of diagnostic assays developed for 2019-ncov, table s <font color='red'>no effective specific antivirals or drug combinations</font> </div></td>\n",
       "      <td>0.515089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A brief review of antiviral drugs evaluated in registered clinical trials for COVID-19</td>\n",
       "      <td>Drifa Belhadi</td>\n",
       "      <td><div> note : iv : intravenous ; sc : subcutaneous <font color='red'>antiviral</font> </div></td>\n",
       "      <td>0.414440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[3]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "-7q5nJn6hqK7",
    "outputId": "4334a585-dbba-4bce-ab88-72c47d14a8ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: Which non-pharmaceutical interventions limit tramsission</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effect of non-pharmaceutical interventions for containing the COVID-19 outbreak in China</td>\n",
       "      <td>Shengjie Lai</td>\n",
       "      <td><div> <font color='red'>the covid-19 outbreak containment strategies in china</font>  based on non-pharmaceutical interventions (npis) appear to be effective.</div></td>\n",
       "      <td>0.364703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Department of Occupational and Environmental Health</td>\n",
       "      <td>(</td>\n",
       "      <td><div> we developed a susceptible-exposed-infectious-recovered model to study the epidemic and evaluate the impact of  <font color='red'>interventions</font> </div></td>\n",
       "      <td>0.360256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predicting support for non-pharmaceutical interventions during infectious outbreaks: a four region analysis</td>\n",
       "      <td>Francesca Matthews Pillemer</td>\n",
       "      <td><div> it is speculated here that some public health interventions may serve as ' gateway ' exposures to  <font color='red'>future public health interventions</font> ..</div></td>\n",
       "      <td>0.359566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study</td>\n",
       "      <td>Joseph Wu</td>\n",
       "      <td><div> here, we provide an estimate of the size of the epidemic in wuhan on the basis of the number of cases exported from wuhan to cities outside mainland china and forecast the extent of the domestic and global public health risks of epidemics, accounting for  <font color='red'>social and non-pharmaceutical prevention</font>  interventions</div></td>\n",
       "      <td>0.309415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The impact of non-pharmaceutical interventions for 2009 H1N1 influenza on travel intentions: A model of goal-directed behavior</td>\n",
       "      <td>Choong-Ki Lee</td>\n",
       "      <td><div> the model found that desire, perceived behavioral control, frequency of past behavior, and non-pharmaceutical interventions predicted tourists ' intention but  <font color='red'>perceptions of 2009 h1n1 had nil effect on desire and intention</font> .</div></td>\n",
       "      <td>0.308177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An optimal control theory approach to non-pharmaceutical interventions</td>\n",
       "      <td>Feng Lin</td>\n",
       "      <td><div> these interventions dampen  <font color='red'>virus spread by reducing contact between infected and susceptible persons</font> .</div></td>\n",
       "      <td>0.254112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SENTINEL EVENT SURVEILLANCE TO ESTIMATE TOTAL SARS-COV-2 INFECTIONS, UNITED STATES A PREPRINT</td>\n",
       "      <td>Andrew Lover</td>\n",
       "      <td><div> our forecast predicts that a very substantial number of infections are undetected, and  <font color='red'>without extensive and far-reaching non-pharmaceutical interventions, the number of infections should be expected to grow at an exponential rate</font> </div></td>\n",
       "      <td>0.245341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pandemic preparedness: perceptions of vulnerable migrants in Thailand towards WHO-recommended non-pharmaceutical interventions: a cross-sectional study</td>\n",
       "      <td>Jason Hickey</td>\n",
       "      <td><div>, using a thermometer, wearing a face mask) and  <font color='red'>inadequate hand washing and household disinfection practices</font> .</div></td>\n",
       "      <td>0.171863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 512). Running this sequence through the model will result in indexing errors\n",
      " 12%|█▎        | 1/8 [00:10<01:15, 10.74s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (4579 > 512). Running this sequence through the model will result in indexing errors\n",
      " 25%|██▌       | 2/8 [00:37<01:33, 15.52s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (10465 > 512). Running this sequence through the model will result in indexing errors\n",
      " 38%|███▊      | 3/8 [01:38<02:26, 29.21s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (7004 > 512). Running this sequence through the model will result in indexing errors\n",
      " 50%|█████     | 4/8 [02:20<02:11, 32.94s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (5349 > 512). Running this sequence through the model will result in indexing errors\n",
      " 62%|██████▎   | 5/8 [02:51<01:37, 32.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6320 > 512). Running this sequence through the model will result in indexing errors\n",
      " 75%|███████▌  | 6/8 [03:28<01:07, 33.80s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (8562 > 512). Running this sequence through the model will result in indexing errors\n",
      " 88%|████████▊ | 7/8 [04:18<00:38, 38.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (5308 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 8/8 [04:49<00:00, 36.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: Which non-pharmaceutical interventions limit tramsission</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTINEL EVENT SURVEILLANCE TO ESTIMATE TOTAL SARS-COV-2 INFECTIONS, UNITED STATES A PREPRINT</td>\n",
       "      <td>Andrew Lover</td>\n",
       "      <td><div> 20037648 doi : medrxiv preprin <font color='red'>without extensive and far-reaching non-pharmaceutical interventions, the number of infections should be expected to grow at an exponential rate</font> </div></td>\n",
       "      <td>0.483931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Department of Occupational and Environmental Health</td>\n",
       "      <td>(</td>\n",
       "      <td><div> 20030593 doi : medrxiv preprin <font color='red'>intra-city and inter-city traffic restriction</font> </div></td>\n",
       "      <td>0.405676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predicting support for non-pharmaceutical interventions during infectious outbreaks: a four region analysis</td>\n",
       "      <td>Francesca Matthews Pillemer</td>\n",
       "      <td><div> gender (table 3 trust, concern, and basic npi support (select significant results <font color='red'>travel screening and restrictions</font> </div></td>\n",
       "      <td>0.372456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An optimal control theory approach to non-pharmaceutical interventions</td>\n",
       "      <td>Feng Lin</td>\n",
       "      <td><div> other important research directions include consideration of population heterogeneity, stochasticity and partial observability in disease outbreak, and developing methods for general terminal time distributions <font color='red'>virus spread by reducing contact between infected and susceptible persons</font> </div></td>\n",
       "      <td>0.314384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The impact of non-pharmaceutical interventions for 2009 H1N1 influenza on travel intentions: A model of goal-directed behavior</td>\n",
       "      <td>Choong-Ki Lee</td>\n",
       "      <td><div> * items were excluded from further analyses <font color='red'>nonpharmaceutical interventions for influenza a (h1n1)</font> </div></td>\n",
       "      <td>0.312520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pandemic preparedness: perceptions of vulnerable migrants in Thailand towards WHO-recommended non-pharmaceutical interventions: a cross-sectional study</td>\n",
       "      <td>Jason Hickey</td>\n",
       "      <td><div> research into the appropriate use of risk communication during inter-pandemic and pandemic periods, combined with ongoing education at the community level, could potentially strengthen individuals ' capacity to participate in pandemic preparedness efforts <font color='red'>inadequate hand washing and household disinfection practices</font> </div></td>\n",
       "      <td>0.267691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Effect of non-pharmaceutical interventions for containing the COVID-19 outbreak in China</td>\n",
       "      <td>Shengjie Lai</td>\n",
       "      <td><div> is the the copyright holder for this preprin <font color='red'>healthcare resources will be limited for treating all cases</font> </div></td>\n",
       "      <td>0.243895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study</td>\n",
       "      <td>Joseph Wu</td>\n",
       "      <td><div> our data purchase agreement with tencent prohibits us from sharing these data with third parties, but interested parties can contact tencent to make the same data purchase <font color='red'>use of face masks and improved personal hygiene</font> </div></td>\n",
       "      <td>0.109115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[4]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaleIcSchqLB",
    "outputId": "df2ae5d5-299c-4642-9fc7-0d446f7542d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.15it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What adjunctive or supportive methods can help patients</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emergent severe acute respiratory distress syndrome caused by adenovirus type 55 in immunocompetent adults in 2013: a prospective observational study</td>\n",
       "      <td>Bing Sun</td>\n",
       "      <td><div> the clinical features and outcomes of the most critically ill patients with severe acute respiratory distress syndrome (ards) caused by hadv-55 requiring  <font color='red'>invasive mechanical ventilation (imv) and / or extracorporeal membrane oxygenation</font>  (ecmo) are lacking.</div></td>\n",
       "      <td>0.521152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intravenous vitamin C as adjunctive therapy for enterovirus/rhinovirus induced acute respiratory distress syndrome</td>\n",
       "      <td>Alpha Fowler</td>\n",
       "      <td><div> this report outlines the first use of high dose intravenous vitamin c as an  <font color='red'>interventional therapy</font>  for ards, resulting from enterovirus / rhinovirus respiratory infection.</div></td>\n",
       "      <td>0.458741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extracorporeal membrane oxygenation for severe Middle East respiratory syndrome coronavirus</td>\n",
       "      <td>Mohammed Alshahrani</td>\n",
       "      <td><div> the objective of this study is to compare the outcomes of mers-cov patients before and after the availability of  <font color='red'>extracorporeal membrane oxygenation</font>  (ecmo) as a rescue therapy in severely hypoxemic patients who failed conventional strategies</div></td>\n",
       "      <td>0.450459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extracorporeal membrane oxygenation with prone position ventilation successfully rescues infantile pertussis: a case report and literature review</td>\n",
       "      <td>Jingyi Shi</td>\n",
       "      <td><div> pertussis infection who developed ards was treated by  <font color='red'>extracorporeal membrane oxygenation (ecmo)</font> .</div></td>\n",
       "      <td>0.415919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobile ECMO team for inter-hospital transportation of patients with ARDS: a retrospective case series</td>\n",
       "      <td>Alberto Lucchini</td>\n",
       "      <td><div> 29 patients (69 %) were transported with  <font color='red'>extracorporeal membrane oxygenation support</font> , while 13 patients (31 %) were transported with conventional ventilation.</div></td>\n",
       "      <td>0.324622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Application of extracorporeal membrane oxygenation in patients with severe acute respiratory distress syndrome induced by avian influenza A (H7N9) viral pneumonia: national data from the Chinese multicentre collaboration</td>\n",
       "      <td>Linna Huang</td>\n",
       "      <td><div> 05) after 48 h on  <font color='red'>ecmo support</font> .</div></td>\n",
       "      <td>0.315255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3772 > 512). Running this sequence through the model will result in indexing errors\n",
      " 17%|█▋        | 1/6 [00:22<01:53, 22.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3216 > 512). Running this sequence through the model will result in indexing errors\n",
      " 33%|███▎      | 2/6 [00:41<01:25, 21.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3621 > 512). Running this sequence through the model will result in indexing errors\n",
      " 50%|█████     | 3/6 [01:02<01:03, 21.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (5711 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 4/6 [01:34<00:49, 24.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3340 > 512). Running this sequence through the model will result in indexing errors\n",
      " 83%|████████▎ | 5/6 [01:53<00:22, 22.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3486 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 6/6 [02:12<00:00, 22.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What adjunctive or supportive methods can help patients</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extracorporeal membrane oxygenation for severe Middle East respiratory syndrome coronavirus</td>\n",
       "      <td>Mohammed Alshahrani</td>\n",
       "      <td><div> until more data are available, ecmo could be considered as a rescue therapy in selected mers-cov patients with refractory hypoxemia <font color='red'>adjunctive therapies</font> </div></td>\n",
       "      <td>0.561469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extracorporeal membrane oxygenation with prone position ventilation successfully rescues infantile pertussis: a case report and literature review</td>\n",
       "      <td>Jingyi Shi</td>\n",
       "      <td><div> these need further investigation in cased with severe pertussis treated by  <font color='red'>ecmo supporting</font> .</div></td>\n",
       "      <td>0.503010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emergent severe acute respiratory distress syndrome caused by adenovirus type 55 in immunocompetent adults in 2013: a prospective observational study</td>\n",
       "      <td>Bing Sun</td>\n",
       "      <td><div> sequential dynamic analysis is needed to determine the relationship between hadv-55 viremia and treatment response <font color='red'>concomitant medications, respiratory support</font> </div></td>\n",
       "      <td>0.487314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intravenous vitamin C as adjunctive therapy for enterovirus/rhinovirus induced acute respiratory distress syndrome</td>\n",
       "      <td>Alpha Fowler</td>\n",
       "      <td><div> this is an interesting report of use of high dose intravenous vitamin c in ards <font color='red'>extracorporeal membrane oxygenation</font> </div></td>\n",
       "      <td>0.465333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobile ECMO team for inter-hospital transportation of patients with ARDS: a retrospective case series</td>\n",
       "      <td>Alberto Lucchini</td>\n",
       "      <td><div> in order to achieve this goal, four factors seem to be crucial : identification of a vehicle with specific tech features, systematic and precise settings of equipment, a toolsystem to sort out equipment and a dedicated training program for nurses involved in these missions <font color='red'>extracorporeal respiratory support</font> </div></td>\n",
       "      <td>0.383449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Application of extracorporeal membrane oxygenation in patients with severe acute respiratory distress syndrome induced by avian influenza A (H7N9) viral pneumonia: national data from the Chinese multicentre collaboration</td>\n",
       "      <td>Linna Huang</td>\n",
       "      <td><div> the ph and paco 2 did not significantly differ between the two groups during ecmo therapy, while patients who eventually weaned successfully from ecmo had a gradual ascending tendency in pao 2 at 48 and 72 h on ecmo and a sustained low level of lactate after ecmo <font color='red'>supported by ecmo</font> </div></td>\n",
       "      <td>0.311465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[5]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FELK-PJhqLF",
    "outputId": "b3c93df5-fc15-411f-e1d0-a04d75800eca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review</td>\n",
       "      <td>Junxiong Pang</td>\n",
       "      <td><div> however,  <font color='red'>serological assays as well as point-of-care testing kits</font>  have not been developed but are likely in the near future.</div></td>\n",
       "      <td>0.566219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Potential T-cell and B-cell Epitopes of 2019-nCoV</td>\n",
       "      <td>Ethan Fast</td>\n",
       "      <td><div> here we use  <font color='red'>computational tools from structural biology and machine learning</font>  to identify 2019-ncov t-cell and b-cell epitopes based on viral protein antigen presentation and antibody binding properties.</div></td>\n",
       "      <td>0.539724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Genome Detective Coronavirus Typing Tool for rapid identification and characterization of novel coronavirus genomes Short title: Automated tool for phylogenetic and mutational analysis of coronaviruses genomes</td>\n",
       "      <td>Sara Cleemput</td>\n",
       "      <td><div> the tool also allows tracking of new viral mutations as the outbreak expands globally, which may help to accelerate the development of  <font color='red'>novel diagnostics, drugs and vaccines</font> </div></td>\n",
       "      <td>0.518947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genome Detective Coronavirus Typing Tool for rapid identification and characterization of novel coronavirus genomes</td>\n",
       "      <td>Sara Cleemput</td>\n",
       "      <td><div> the tool also allows tracking of new viral mutations as the outbreak expands globally, which may help to accelerate the development of  <font color='red'>novel diagnostics, drugs and vaccines</font>  to stop the covid-19 disease</div></td>\n",
       "      <td>0.507590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rapid colorimetric detection of COVID-19 coronavirus using a reverse tran- scriptional loop-mediated isothermal amplification (RT-LAMP) diagnostic plat- form: iLACO</td>\n",
       "      <td>Lin Yu</td>\n",
       "      <td><div> the accuracy, simplicity and versatility of the new developed method suggests that  <font color='red'>ilaco assays can be conveniently applied with for 2019-ncov threat control, even in those cases where specialized molecular biology equipment is not available</font> </div></td>\n",
       "      <td>0.481791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title Page: 1 Reverse transcription loop-mediated isothermal amplification combined with 2 nanoparticles-based biosensor for diagnosis of COVID-19 3 4 Laboratory of Pediatric Respiratory Infection Disease, National Clinical Research</td>\n",
       "      <td>Xiong Zhu</td>\n",
       "      <td><div> a one-step reverse 34 transcription loop-mediated isothermal amplification (rt-lamp) coupled with 35 nanoparticles-based biosensor (nbs) assay ( <font color='red'>rt-lamp-nbs</font> ) was successfully 36 established for rapidly and accurately diagnosing covid-19.</div></td>\n",
       "      <td>0.399734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3753 > 512). Running this sequence through the model will result in indexing errors\n",
      " 17%|█▋        | 1/6 [00:21<01:49, 21.83s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2810 > 512). Running this sequence through the model will result in indexing errors\n",
      " 33%|███▎      | 2/6 [00:38<01:20, 20.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2422 > 512). Running this sequence through the model will result in indexing errors\n",
      " 50%|█████     | 3/6 [00:52<00:55, 18.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2331 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 4/6 [01:05<00:33, 16.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (7817 > 512). Running this sequence through the model will result in indexing errors\n",
      " 83%|████████▎ | 5/6 [01:51<00:25, 25.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2361 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 6/6 [02:04<00:00, 20.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title: Genome Detective Coronavirus Typing Tool for rapid identification and characterization of novel coronavirus genomes Short title: Automated tool for phylogenetic and mutational analysis of coronaviruses genomes</td>\n",
       "      <td>Sara Cleemput</td>\n",
       "      <td><div> the tool has been able to correctly classify all the recently released ncov-2019 genomes, as well as all the 2002-2003 sars outbreak sequences in conclusion, the genome detective coronavirus typing tool is a web-based and user-friendly software application that allows the identification and characterization of novel coronavirus genomes <font color='red'>novel diagnostics, drugs and vaccines</font> </div></td>\n",
       "      <td>0.527380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genome Detective Coronavirus Typing Tool for rapid identification and characterization of novel coronavirus genomes</td>\n",
       "      <td>Sara Cleemput</td>\n",
       "      <td><div> the tool has been able to correctly classify all the recently released sars-cov-2 genomes, as well as all the 2002-2003 sars outbreak sequences in conclusion, the genome detective coronavirus typing tool is a webbased and user-friendly software application that allows the identification and characterization of novel coronavirus genomes <font color='red'>novel diagnostics, drugs and vaccines</font> </div></td>\n",
       "      <td>0.525417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review</td>\n",
       "      <td>Junxiong Pang</td>\n",
       "      <td><div> com / xxx / s1, table s1 : example of full search strategy in pubmed, table s2 : google search : 2019-ncov diagnostics, table s3 : summary of diagnostic assays developed for 2019-ncov, table s <font color='red'>rapid diagnostic kits</font> </div></td>\n",
       "      <td>0.520540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Potential T-cell and B-cell Epitopes of 2019-nCoV</td>\n",
       "      <td>Ethan Fast</td>\n",
       "      <td><div> we thank all labs 343 contributing to the global efforts of sequencing 2019-ncov sam-344 ples and we attached the full acknowledgment list in si appendix <font color='red'>computational tools from structural biology and machine learning</font> </div></td>\n",
       "      <td>0.416017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rapid colorimetric detection of COVID-19 coronavirus using a reverse tran- scriptional loop-mediated isothermal amplification (RT-LAMP) diagnostic plat- form: iLACO</td>\n",
       "      <td>Lin Yu</td>\n",
       "      <td><div> b : positive signal was visible with the naked eye under blue light <font color='red'>ilaco</font> </div></td>\n",
       "      <td>0.334019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title Page: 1 Reverse transcription loop-mediated isothermal amplification combined with 2 nanoparticles-based biosensor for diagnosis of COVID-19 3 4 Laboratory of Pediatric Respiratory Infection Disease, National Clinical Research</td>\n",
       "      <td>Xiong Zhu</td>\n",
       "      <td><div> 20037796 doi : medrxiv preprin <font color='red'>rt-lamp-nbs</font> </div></td>\n",
       "      <td>0.078285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[6]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eak4f0DrhqLQ",
    "outputId": "a36d2161-a364-4512-99a0-870c5ff097b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:13<00:00,  1.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What collaborations are happening within the research community</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-ME: A 3D Community-Based, Real-Time Collaboration Tool for Scientific Research and Training</td>\n",
       "      <td>A Kolatkar</td>\n",
       "      <td><div>the need for effective collaboration tools is growing as  <font color='red'>multidisciplinary proteome-wide projects and distributed research teams become more common</font> .</div></td>\n",
       "      <td>0.681837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R E V I E W partnership: experiences of co-learning and supporting the healthcare system in Uganda</td>\n",
       "      <td>Open Access</td>\n",
       "      <td><div>  <font color='red'>training and research are a key focus of the partnership and have involved both staff and students of both institutions including guest lectures, seminars and conference presentations</font> .</div></td>\n",
       "      <td>0.592211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emerging respiratory tract infections 2 Emerging infectious diseases and pandemic potential: status quo and reducing risk of global spread</td>\n",
       "      <td>Brian Mccloskey</td>\n",
       "      <td><div>  <font color='red'>collaboration between countries should be encouraged in a way that acknowledges the benefi ts that derive from sharing biological material and establishing equitable collaborative research partnerships</font> .</div></td>\n",
       "      <td>0.588500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fogarty International Center collaborative networks in infectious disease modeling: Lessons learnt in research and capacity building</td>\n",
       "      <td>Martha Nelson</td>\n",
       "      <td><div> together, these programs have  <font color='red'>coordinated international collaborative networks</font>  to advance the study of emerging disease threats and the field of computational epidemic modeling.</div></td>\n",
       "      <td>0.546637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Collaboration between infection control and occupational health in three continents: a success story with international impact</td>\n",
       "      <td>Annalee Yassi</td>\n",
       "      <td><div> this  <font color='red'>international collaboration between occupational health and infection control researchers led to the improvement of the research framework and development of tools, guidelines and information systems</font> .</div></td>\n",
       "      <td>0.532365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A global bibliometric analysis of Plesiomonas- related research (1990 -2017)</td>\n",
       "      <td>Temitope Ekundayoid</td>\n",
       "      <td><div> here, we carried out a bibliometric survey that aimed to examine publication trends in plesiomonas-related research by time and place,  <font color='red'>international collaborative works</font> , identify gaps and suggest directions for future research.</div></td>\n",
       "      <td>0.502882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Need of surveillance response systems to combat Ebola outbreaks and other emerging infectious diseases in African countries</td>\n",
       "      <td>Ernest Tambo</td>\n",
       "      <td><div>iii)  <font color='red'>more research and development in new drug discovery and vaccines</font>  ; and (iv) understanding the involvement of global health to promote the establishment of public health surveillance response systems with functions of early warning, as well as monitoring and evaluation in upholding research-action programmes and innovative interventions</div></td>\n",
       "      <td>0.502012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9528 > 512). Running this sequence through the model will result in indexing errors\n",
      " 14%|█▍        | 1/7 [00:54<05:27, 54.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (4387 > 512). Running this sequence through the model will result in indexing errors\n",
      " 29%|██▊       | 2/7 [01:19<03:48, 45.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (5388 > 512). Running this sequence through the model will result in indexing errors\n",
      " 43%|████▎     | 3/7 [01:50<02:45, 41.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6255 > 512). Running this sequence through the model will result in indexing errors\n",
      " 57%|█████▋    | 4/7 [02:26<01:58, 39.60s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3666 > 512). Running this sequence through the model will result in indexing errors\n",
      " 71%|███████▏  | 5/7 [02:46<01:07, 33.93s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (7319 > 512). Running this sequence through the model will result in indexing errors\n",
      " 86%|████████▌ | 6/7 [03:28<00:36, 36.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6607 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 7/7 [04:06<00:00, 35.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What collaborations are happening within the research community</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R E V I E W partnership: experiences of co-learning and supporting the healthcare system in Uganda</td>\n",
       "      <td>Open Access</td>\n",
       "      <td><div> the achievements, experiences and prospects of this growing partnership can inform other collaborations in similar settings <font color='red'>development of joint research and collaborative projects</font> </div></td>\n",
       "      <td>0.662740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-ME: A 3D Community-Based, Real-Time Collaboration Tool for Scientific Research and Training</td>\n",
       "      <td>A Kolatkar</td>\n",
       "      <td><div> 82 mb swf <font color='red'>research teams are increasingly interdisciplinary and collaborative among laboratories in different departments and institutions located around the world</font> </div></td>\n",
       "      <td>0.593848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fogarty International Center collaborative networks in infectious disease modeling: Lessons learnt in research and capacity building</td>\n",
       "      <td>Martha Nelson</td>\n",
       "      <td><div> the authors don ' t report any financial and personal conflicts of interest <font color='red'>collaborators are now established as senior researchers</font> </div></td>\n",
       "      <td>0.528086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collaboration between infection control and occupational health in three continents: a success story with international impact</td>\n",
       "      <td>Annalee Yassi</td>\n",
       "      <td><div> this can never be taken for granted <font color='red'>interdisciplinary international collaboration has contributed to produce practical tools such as guidelines, online and face-to-face training products, checklists, research materials, frameworks and a health information system</font> </div></td>\n",
       "      <td>0.505587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerging respiratory tract infections 2 Emerging infectious diseases and pandemic potential: status quo and reducing risk of global spread</td>\n",
       "      <td>Brian Mccloskey</td>\n",
       "      <td><div> we declare no competing interests <font color='red'>collaboration between countries should be encouraged in a way that acknowledges the benefi ts that derive from sharing biological material and establishing equitable collaborative research partnerships</font> </div></td>\n",
       "      <td>0.491351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Need of surveillance response systems to combat Ebola outbreaks and other emerging infectious diseases in African countries</td>\n",
       "      <td>Ernest Tambo</td>\n",
       "      <td><div> hence, developing, scaling up and strengthening all aspects of the outbreak surveillance response system including contact tracking, public information and community mobilization, case management and infection prevention and control, and effective coordination <font color='red'>communication and networking</font> </div></td>\n",
       "      <td>0.404570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A global bibliometric analysis of Plesiomonas- related research (1990 -2017)</td>\n",
       "      <td>Temitope Ekundayoid</td>\n",
       "      <td><div> (tif) s <font color='red'>international collaborative works</font> </div></td>\n",
       "      <td>0.400340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[7]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_00uFcLkhqLV",
    "outputId": "505c1f95-c91f-4573-822e-65a394e096ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What are the major ethical issues related pandemic outbreaks</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with only Abstract\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethics for pandemics beyond influenza: Ebola, drug- resistant tuberculosis, and anticipating future ethical challenges in pandemic preparedness and response</td>\n",
       "      <td>Maxwell Smith</td>\n",
       "      <td><div> <font color='red'>the unprecedented outbreak of ebola virus disease (evd) in west africa has raised several novel ethical issues for global outbreak preparedness. it has also illustrated that familiar ethical issues in infectious disease management endure despite considerable efforts to understand and mitigate such issues in the wake of past outbreaks. to improve future global outbreak preparedness and response, we must examine these shortcomings and reflect upon the current state of ethical preparedness. to this end, we focus our efforts in this article on the examination of one substantial area : ethical guidance in pandemic plans. we argue that, due in part to their focus on considerations arising specifically in relation to pandemics of influenza origin, pandemic plans and their existing ethical guidance are ill-equipped to anticipate and facilitate the navigation of unique ethical challenges that may arise in other infectious disease pandemics. we proceed by outlining three reasons why this is so, and situate our analysis in the context of the evd outbreak and the threat posed by drug-resistant tuberculosis : (1) different infectious diseases have distinct characteristics that challenge anticipated or existing modes of pandemic prevention, preparedness, response, and recovery</font> , (2) clear, transparent, context-specific ethical reasoning and justification within current influenza pandemic plans are lacking, and (3) current plans neglect the context of how other significant pandemics may manifest.</div></td>\n",
       "      <td>0.710840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Risk Management and Healthcare Policy Dovepress Critical role of ethics in clinical management and public health response to the West Africa Ebola epidemic</td>\n",
       "      <td>Morenike Folayan</td>\n",
       "      <td><div> ethical issues related to prevention and containment include the  <font color='red'>appropriateness and scope of quarantine and isolation within and outside affected countries</font> .</div></td>\n",
       "      <td>0.689570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ethics-sensitivity of the Ghana national integrated strategic response plan for pandemic influenza</td>\n",
       "      <td>Amos Laar</td>\n",
       "      <td><div>background :  <font color='red'>many commentators call for a more ethical approach to planning for influenza pandemics</font> .</div></td>\n",
       "      <td>0.681166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Special Issue Pandethics</td>\n",
       "      <td>M Selgelid</td>\n",
       "      <td><div>this paper explains the ethical importance of infectious diseases, and reviews four major ethical issues associated with pandemic influenza :  <font color='red'>the obligation of individuals to avoid infecting others, healthcare workers ' ' duty to treat ', allocation of scarce resources, and coercive social distancing measures</font> .</div></td>\n",
       "      <td>0.659091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The prospect of pandemic influenza: Why should the optometrist be concerned about a public health problem?</td>\n",
       "      <td>Gregory Hom</td>\n",
       "      <td><div> the  <font color='red'>ethical and legal issues surrounding control of a pandemic influenza</font>  and the prospect of telemedicine as a form of social distancing are also discussed.</div></td>\n",
       "      <td>0.639385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BMC Medical Ethics On pandemics and the duty to care: whose duty? who cares?</td>\n",
       "      <td>Carly Ruderman</td>\n",
       "      <td><div> despite this challenge,  <font color='red'>professional codes of ethics are silent on the issue of duty to care during communicable disease outbreaks</font> , thus providing no guidance on what is expected of hcps or how they ought to approach their duty to care in the face of risk</div></td>\n",
       "      <td>0.615739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>653-662 Lor et al</td>\n",
       "      <td>Aun Lor</td>\n",
       "      <td><div> methods : we reviewed the meeting reports, notes and stories and mapped outcomes to the key ethical challenges for pandemic influenza response described in the world health organization ' s (who ' s) guidance, ethical considerations in developing a public health response to pandemic influenza :  <font color='red'>transparency and public engagement, allocation of resources, social distancing, obligations to and of healthcare workers, and international collaboration</font> .</div></td>\n",
       "      <td>0.605742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The duty to care in an influenza pandemic: A qualitative study of Canadian public perspectives</td>\n",
       "      <td>Cécile Bensimon</td>\n",
       "      <td><div> this study involved three townhall meetings held between february 2008 and may 2010 in three urban settings in canada in order to probe lay citizens ' views about ethical issues related to pandemic influenza, including  <font color='red'>issues surrounding the duty to care</font> .</div></td>\n",
       "      <td>0.492084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fight or Flight: The Ethics of Emergency Physician Disaster Response</td>\n",
       "      <td>Kenneth Iserson</td>\n",
       "      <td><div> however, we need to ask :  <font color='red'>should they, and will they, work rather than flee</font> </div></td>\n",
       "      <td>0.278741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pandémie grippale A/H5N1 et niveau de préparation du Niger : une étude sur les connaissances des soignants et l'organisation générale des soins Preparedness for influenza A/H5N1 pandemic in Niger: a study on health care workers' knowledge and global organization of health activities</td>\n",
       "      <td>E D&apos;</td>\n",
       "      <td><div> cette etudela premiere a notre connaissance a explorer ces questions dans le contexte africaina d ' abord mis en lumiere  <font color='red'>une certaine maitrise des connaissances theoriques sur la grippe aviaire par les soignants. cependant, au-dela des savoirs theoriques, l ' enquete a egalement permis d ' identifier des limites importantes compromettant les capacites de prevention et de lutte contre une pandemie grippale, notamment en termes d ' organisation des soins et de controle du risque infectieux hospitalier</font> .</div></td>\n",
       "      <td>0.198279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (4486 > 512). Running this sequence through the model will result in indexing errors\n",
      " 10%|█         | 1/10 [00:25<03:49, 25.47s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6877 > 512). Running this sequence through the model will result in indexing errors\n",
      " 20%|██        | 2/10 [01:04<03:55, 29.50s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (8332 > 512). Running this sequence through the model will result in indexing errors\n",
      " 30%|███       | 3/10 [01:51<04:03, 34.85s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (11291 > 512). Running this sequence through the model will result in indexing errors\n",
      " 40%|████      | 4/10 [02:55<04:21, 43.55s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6307 > 512). Running this sequence through the model will result in indexing errors\n",
      " 50%|█████     | 5/10 [03:31<03:26, 41.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (4974 > 512). Running this sequence through the model will result in indexing errors\n",
      " 60%|██████    | 6/10 [04:00<02:30, 37.66s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (7220 > 512). Running this sequence through the model will result in indexing errors\n",
      " 70%|███████   | 7/10 [04:42<01:56, 38.87s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (7394 > 512). Running this sequence through the model will result in indexing errors\n",
      " 80%|████████  | 8/10 [05:25<01:20, 40.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (8288 > 512). Running this sequence through the model will result in indexing errors\n",
      " 90%|█████████ | 9/10 [06:13<00:42, 42.49s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (6063 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 10/10 [06:48<00:00, 40.85s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What are the major ethical issues related pandemic outbreaks</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search with full paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>BERT-SQuAD Answer with Highlights</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethics for pandemics beyond influenza: Ebola, drug- resistant tuberculosis, and anticipating future ethical challenges in pandemic preparedness and response</td>\n",
       "      <td>Maxwell Smith</td>\n",
       "      <td><div> we hope that this occurs, and that it proceeds by considering the ethical issues that may exist in infectious disease pandemics beyond influenza <font color='red'>testing investigational agents in vaccine trials</font> </div></td>\n",
       "      <td>0.667411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>653-662 Lor et al</td>\n",
       "      <td>Aun Lor</td>\n",
       "      <td><div> they affirm the notion that, cultural differences notwithstanding, people and countries will come together to combat the health threat a pandemic influenza poses to all, when fair procedures are established that give those affected a seat at the table and a voice <font color='red'>low literacy level, poverty, and trust of and / or deference to health authorities</font> </div></td>\n",
       "      <td>0.651199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Risk Management and Healthcare Policy Dovepress Critical role of ethics in clinical management and public health response to the West Africa Ebola epidemic</td>\n",
       "      <td>Morenike Folayan</td>\n",
       "      <td><div> the authors report no conflicts of interest in this <font color='red'>appropriateness and scope of quarantine and isolation within and outside affected countries</font> </div></td>\n",
       "      <td>0.626934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The prospect of pandemic influenza: Why should the optometrist be concerned about a public health problem?</td>\n",
       "      <td>Gregory Hom</td>\n",
       "      <td><div> potentially dangerous flu strains are brewing, and now is the opportunity to assess our vulnerabilities as individuals, families, communities, nations, and health care professionals <font color='red'>need for preservation of infrastructure and public order (law enforcement), provision of a healthy pool of health care providers tending to the ill, and protection of the more vulnerable members of society</font> </div></td>\n",
       "      <td>0.611413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethics-sensitivity of the Ghana national integrated strategic response plan for pandemic influenza</td>\n",
       "      <td>Amos Laar</td>\n",
       "      <td><div> in this scenario the virus could arrive in ghana via migratory birds but also (and perhaps more plausibly) by the arrival in ghana of infected individuals traveling from other countries <font color='red'>recurring tension in public health between the rights of individual liberties versus public health promotion</font> </div></td>\n",
       "      <td>0.605615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Special Issue Pandethics</td>\n",
       "      <td>M Selgelid</td>\n",
       "      <td><div> none declared <font color='red'>the obligation of individuals to avoid infecting others, healthcare workers ' ' duty to treat ', allocation of scarce resources, and coercive social distancing measures</font> </div></td>\n",
       "      <td>0.475165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMC Medical Ethics On pandemics and the duty to care: whose duty? who cares?</td>\n",
       "      <td>Carly Ruderman</td>\n",
       "      <td><div> indeed, the time to address the ethical duty to provide care is at hand-before the arrival of the next public health emergency <font color='red'>ethical duty to provide care during public health emergencies</font> </div></td>\n",
       "      <td>0.418049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pandémie grippale A/H5N1 et niveau de préparation du Niger : une étude sur les connaissances des soignants et l'organisation générale des soins Preparedness for influenza A/H5N1 pandemic in Niger: a study on health care workers' knowledge and global organization of health activities</td>\n",
       "      <td>E D&apos;</td>\n",
       "      <td><div> conflit d ' interet : les auteurs declarent n ' avoir aucun conflit d ' interet <font color='red'>questions de pandemies grippales (h5n1 et h1n1) [ 11,22,24,31 ] et de sras [ 7,14,29 ]</font> </div></td>\n",
       "      <td>0.399852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fight or Flight: The Ethics of Emergency Physician Disaster Response</td>\n",
       "      <td>Kenneth Iserson</td>\n",
       "      <td><div> see the manuscript submission agreement in this issue for examples of specific conflicts covered by this statement <font color='red'>ethical and social reasons why health care professionals should stay to treat patients</font> </div></td>\n",
       "      <td>0.390590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The duty to care in an influenza pandemic: A qualitative study of Canadian public perspectives</td>\n",
       "      <td>Cécile Bensimon</td>\n",
       "      <td><div> what is more, it illustrates the urgent need for policy-makers and regulators to get clarity on obligations, responsibilities, and accountability in the application of hcps ' duty to care during times of universal vulnerability <font color='red'>issues surrounding the duty to care</font> </div></td>\n",
       "      <td>0.344657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = all_topics[8]\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
    "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTGyQql2hqLc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of BERT_Verion_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
