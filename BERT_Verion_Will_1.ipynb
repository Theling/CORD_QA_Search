{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of BERT_Verion_1.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCU1sltzhqJX",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBpm_qG0WqXX",
        "colab_type": "text"
      },
      "source": [
        "  As everyone unfortunately knows, COVID-19 has brought the world to a standstill and is the worst pandemic in a century. Because of this, the world health community has devoted an unprecedented amount of resources towards the study, containment, and hopefully the eradication of this disease. However, this also means that an unprecedented amount of data has been produced, much more than researchers and journalists can sort through by hand. Thus, this contest was started by Kaggle to help develop new methods of sorting through the massive amount of papers being written on the subject. Our contribution is to make major improvements on the method developed by \"dirktheeng\" in their “Anserini+BERT-SQuAD for Semantic Corpus Search” notebook. The link to their notebook can be found here: https://www.kaggle.com/dirktheeng\n",
        "  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BUhsK1XhqJd",
        "colab_type": "text"
      },
      "source": [
        "## Methodology\n",
        "\n",
        "Our methodology is very similar to the one used in the original notebook. The basic idea is to use the BERT model to perform basic question and answer tasks, i.e. the user can ask the model a question, and it will return what it thinks the best answer is from a database. In the case of the original notebook, this model was used to scan through numerous paper abstracts to find which abstracts best answer the question. To do this, the model would take in a question plus candidate abstract and output a start index, end index, and its confidence value. The start index is where the most relevant part of the text starts, the end index is where it ends, and the confidence value is how sure it is that’s the right answer. The model then does this for the rest of the abstracts, ranks them based on confidence values, and returns the answer it’s most confident of, along with the paper that it comes from. This is a perfectly fine model, however, there were a few key improvements that we were able to make.\n",
        "\n",
        "First, we extended the model to search the entire paper, not just the abstract. The BERT model is only able to handle text shorter than 512 words. When factoring in the length of the question statement, this means that the original model could only handle chunks of text shorter than 500 words. Since abstracts are always shorter than that, the length constraints weren’t an issue for the original model. However, there is a lot of potentially useful information in the body of these papers, so it would better if the model could scan this as well. To do this, we simply broke up longer text into chucks less than 500 words, and ran each smaller chunk through the model separately. Thus, we were able to find which part of the paper was most relevant and return it. Also, this requires much more data than the original model’s database, which only included the abstracts. So, we added in a way to upload the body text, match it to the right abstract, merge the two, and pass the full text on to the model. This allows our improved model to handle much more data.\n",
        "\n",
        "Second, there was a major bug in the original model where it could return nonsensical index ranges where the start index came after the end index. For example, if the model returns a range of [26,13], it’s impossible to reconstruct the answer from that. We came up with a rather ingenious solution to this problem. If the model returns a range such as [26,13], our new model fix that by breaking the original text chunk into two parts, say [0,13] and [26,n-1] (n is the length of the original text chunk). Then, it will find two new potential answer ranges, say [7,13] and [26,31], and return the one it’s more confident of. Thus, our new model fixes this bug and is more reliable. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCR3EVRVhqJf",
        "colab_type": "text"
      },
      "source": [
        "## Contribution\n",
        "* 1.\n",
        "* 2.\n",
        "* 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EChlz0IzhqJn",
        "colab_type": "text"
      },
      "source": [
        "## Setup Envirnment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O5y4EoHh7Bn",
        "colab_type": "text"
      },
      "source": [
        "Note, this is the line of code you need to run when using google Colab. On other platforms, this may be different.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHhUCGFUh5Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8T9L1I9igH6",
        "colab_type": "code",
        "outputId": "1e3afd46-e206-4450-9414-06a15257492d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        }
      },
      "source": [
        "!pip install pyserini\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyserini\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/67/f11bd9c9afcef667b816864a38cea950d1245fc56e4617714530ba4fdccc/pyserini-0.9.0.0-py3-none-any.whl (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 68kB/s \n",
            "\u001b[?25hCollecting pyjnius\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/50/098cb5fb76fb7c7d99d403226a2a63dcbfb5c129b71b7d0f5200b05de1f0/pyjnius-1.3.0-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from pyserini) (0.29.17)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pyjnius->pyserini) (1.12.0)\n",
            "Installing collected packages: pyjnius, pyserini\n",
            "Successfully installed pyjnius-1.3.0 pyserini-0.9.0.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 38.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=75ca1007970213f732288ee5a45bf274c2b1e21297e9f8c8fcde512d1a6f91f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDbOsNHhqIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import pandas as pd\n",
        "from pyserini.search import pysearch\n",
        "import numpy as np\n",
        "from BERT_func import BERT_SQUAD_QA\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEn87vSqUpVW",
        "colab_type": "text"
      },
      "source": [
        "Note: You will need to load in a file called \"database.json\" into your workspace for this notebook to work. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2YESbCtuZjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%capture\n",
        "!wget -O lucene.tar.gz https://www.dropbox.com/s/d6v9fensyi7q3gb/lucene-index-covid-2020-04-03.tar.gz?dl=0\n",
        "!tar xvfz lucene.tar.gz\n",
        "minDate = '2020/04/02'\n",
        "luceneDir = 'lucene-index-covid-2020-04-03/'\n",
        "torch_device = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaTyf40WhqJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#You can just run this cell if you ran the previous cell or already have 'lucene-index-covid-2020-04-03/' set up\n",
        "torch_device = 'cpu'\n",
        "minDate = '2020/04/02'\n",
        "luceneDir = 'lucene-index-covid-2020-04-03/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8AUYQMThqJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QA_MODEL = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "QA_TOKENIZER = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "QA_MODEL.to(torch_device)\n",
        "QA_MODEL.eval()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsjV9_CvlsEL",
        "colab_type": "text"
      },
      "source": [
        "Note, we need to actually get the data first. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1wY9OHbIfqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/ # There is no need to run this if using google Colab, since the content folder should already exist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2TqHpUqlVgN",
        "colab_type": "code",
        "outputId": "16d22473-23b6-464c-830e-2b1a6cc3087b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!mkdir /content/kaggle/\n",
        "!mkdir /content/kaggle/working/\n",
        "!mkdir /content/kaggle/working/sentence_wise_email/\n",
        "!mkdir /content/kaggle/working/sentence_wise_email/module/\n",
        "!mkdir /content/kaggle/working/sentence_wise_email/module/module_useT\n",
        "# Download the module, and uncompress it to the destination folder. \n",
        "!curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | tar -zxvC /content/kaggle/working//sentence_wise_email/module/module_useT"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "./\n",
            "./tfhub_module.pb\n",
            "./variables/\n",
            "./variables/variables.data-00000-of-00001\n",
            " 92  745M   92  689M    0     0  52.8M      0  0:00:14  0:00:13  0:00:01 54.7M./variables/variables.index\n",
            "./assets/\n",
            "./saved_model.pb\n",
            "100  745M  100  745M    0     0  53.2M      0  0:00:14  0:00:14 --:--:-- 56.5M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjqqZffmlS8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/result/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHYlnTYxhqJ_",
        "colab_type": "text"
      },
      "source": [
        "## Embbeding Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBfNRXWhqKA",
        "colab_type": "code",
        "outputId": "2884c47d-06e8-41b7-ee54-8c38e4dca51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "def embed_useT(module):\n",
        "    with tf.Graph().as_default():\n",
        "        sentences = tf.compat.v1.placeholder(tf.string)\n",
        "        embed = hub.Module(module)\n",
        "        embeddings = embed(sentences)\n",
        "        session = tf.compat.v1.train.MonitoredSession()\n",
        "    return lambda x: session.run(embeddings, {sentences: x})\n",
        "embed_fn = embed_useT('/content/kaggle/working/sentence_wise_email/module/module_useT')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoC4JSL7hqKI",
        "colab_type": "text"
      },
      "source": [
        "## Display the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ksYc3-hqKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workingPath = '/content/kaggle/working'\n",
        "import pandas as pd\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "#from summarizer import Summarizer\n",
        "#summarizerModel = Summarizer()\n",
        "def displayResults(hit_dictionary, answers, question, abst):\n",
        "    \n",
        "    question_HTML = '<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: '+question+'</div>'\n",
        "    #all_HTML_txt = question_HTML\n",
        "    confidence = list(answers.keys())\n",
        "    confidence.sort(reverse=True)\n",
        "    \n",
        "    confidence = list(answers.keys())\n",
        "    confidence.sort(reverse=True)\n",
        "    \n",
        "\n",
        "    for c in confidence:\n",
        "        if c>0 and c <= 1 and len(answers[c]['answer']) != 0:\n",
        "            rowData = []\n",
        "#             idx = answers[c]['idx']\n",
        "#             title = hit_dictionary[idx]['title']\n",
        "#             authors = hit_dictionary[idx]['authors'] + ' et al.'\n",
        "\n",
        "            \n",
        "            full_abs = answers[c]['abstract_bert']\n",
        "            bert_ans = answers[c]['answer']\n",
        "            #print(full_abs)\n",
        "            \n",
        "            \n",
        "            split_abs = full_abs.split(bert_ans)\n",
        "            sentance_beginning = split_abs[0][split_abs[0].rfind('.')+1:]\n",
        "            #print (sentance_beginning)\n",
        "            if len(split_abs) == 1:\n",
        "                sentance_end_pos = len(full_abs)\n",
        "                sentance_end =''\n",
        "            else:\n",
        "                sentance_end_pos = split_abs[1].find('. ')+1\n",
        "                if sentance_end_pos == 0:\n",
        "                    sentance_end = split_abs[1]\n",
        "                else:\n",
        "                    sentance_end = split_abs[1][:sentance_end_pos]\n",
        "                \n",
        "            #sentance_full = sentance_beginning + bert_ans+ sentance_end\n",
        "            answers[c]['full_answer'] = sentance_beginning+bert_ans+sentance_end\n",
        "            answers[c]['sentence_beginning'] = sentance_beginning\n",
        "            answers[c]['sentence_end'] = sentance_end\n",
        "            #answers[c]['title'] = title\n",
        "            #answers[c]['doi'] = doi\n",
        "        else:\n",
        "            answers.pop(c)\n",
        "            \n",
        "    #print(list(answers.keys()))\n",
        "    \n",
        "    ## now rerank based on semantic similarity of the answers to the question\n",
        "    cList = list(answers.keys())\n",
        "    allAnswers = [answers[c]['full_answer'] for c in cList]\n",
        "    #print('all:', allAnswers)\n",
        "    \n",
        "    messages = [question]+allAnswers\n",
        "    \n",
        "    encoding_matrix = embed_fn(messages)\n",
        "    similarity_matrix = np.inner(encoding_matrix, encoding_matrix)\n",
        "    rankings = similarity_matrix[1:,0]\n",
        "    \n",
        "    for i,c in enumerate(cList):\n",
        "        answers[rankings[i]] = answers.pop(c)\n",
        "    \n",
        "    ## now form pandas dv\n",
        "    confidence = list(answers.keys())\n",
        "    confidence.sort(reverse=True)\n",
        "    pandasData = []\n",
        "    ranked_aswers = []\n",
        "    for c in confidence:\n",
        "        rowData=[]\n",
        "        title = answers[c]['title']\n",
        "        author = answers[c]['author']\n",
        "        doi = None\n",
        "        #idx = answers[c]['idx']\n",
        "        #rowData += [idx]            \n",
        "        sentance_html = '<div>' +answers[c]['sentence_beginning'] + \" <font color='red'>\"+answers[c]['answer']+\"</font> \"+answers[c]['sentence_end']+'</div>'\n",
        "        #print (sentance_html)\n",
        "        rowData += [title,author, sentance_html, c]\n",
        "        pandasData.append(rowData)\n",
        "        ranked_aswers.append(' '.join([answers[c]['full_answer']]))\n",
        "    \n",
        "    pdata2 = pandasData\n",
        "        \n",
        "    \n",
        "    display(HTML(question_HTML))\n",
        "    \n",
        "    df = pd.DataFrame(pdata2, columns = ['Title','Authors', 'BERT-SQuAD Answer with Highlights', 'Confidence'])\n",
        "    tit = '_'.join(question.split(' '))\n",
        "    if abst:\n",
        "        df.to_csv('./result/Abs+' + tit + '.csv')\n",
        "        print('Search with only Abstract')\n",
        "    else:\n",
        "        df.to_csv('./result/Full+' + tit + '.csv')\n",
        "        print ('Search with full paper')\n",
        "        \n",
        "    display(HTML(df.to_html(render_links=True, escape=False)))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPHTEPNphqKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Display_all(query, keywords, abst):\n",
        "    \n",
        "    #search with luceneDir database by anserini\n",
        "    searcher = pysearch.SimpleSearcher(luceneDir)\n",
        "    hits = searcher.search(query + '. ' + keywords)\n",
        "    n_hits = len(hits)\n",
        "    #finds the most relvent docs from the database\n",
        "    \n",
        "    #get database by ourselves, this is what database.json does\n",
        "    with open('database.json', 'r') as fp:\n",
        "        database = json.loads(fp.read())\n",
        "        \n",
        "    ID = []\n",
        "    for i in range(0, n_hits):\n",
        "        doc_json = json.loads(hits[i].raw)\n",
        "        try:\n",
        "            ID.append(doc_json['paper_id'])\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    database_df = pd.DataFrame(database).T\n",
        "    \n",
        "    database_df['abs_text'] = database_df.abstract+ database_df['full-text']\n",
        "    #this part adds in the full text\n",
        "\n",
        "    \n",
        "    #match with own database, this compares the two results\n",
        "    ID_real = []\n",
        "    for Id in ID:\n",
        "        if abst:\n",
        "            if Id in database and ~database_df.loc[Id].isna().abstract:\n",
        "                #print(database_df.loc[Id].isna().abstract)\n",
        "                ID_real.append(Id)\n",
        "        else:\n",
        "            if Id in database and ~database_df.loc[Id].isna()['full-text']:\n",
        "                ID_real.append(Id)\n",
        "            \n",
        "    #print (ID_real)\n",
        "    \n",
        "    hit_dictionary = database_df.loc[ID_real].to_dict('index')\n",
        "    \n",
        "    QA_model = BERT_SQUAD_QA(QA_TOKENIZER, QA_MODEL)\n",
        "    ans = QA_model.search_abstracts(hit_dictionary, query, abst)\n",
        "    \n",
        "    displayResults(hit_dictionary, ans, query, abst)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM-4p6iIhqKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_topics=[\n",
        "    'What is known about transmission, incubation, and environmental stability?',\n",
        "    'What do we know about COVID-19 risk factors?',\n",
        "    'What do we know about virus genetics, origin, and evolution?',\n",
        "    'What do we know about vaccines and therapeutics?',\n",
        "    'What do we know about non-pharmaceutical interventions?',\n",
        "    'What has been published about medical care?',\n",
        "    'What do we know about diagnostics and surveillance?',\n",
        "    'What has been published about information sharing and inter-sectoral collaboration?',\n",
        "    'What has been published about ethical and social science considerations?'\n",
        "]\n",
        "topic_area = {}\n",
        "\n",
        "#0\n",
        "#What is known about transmission, incubation, and environmental stability?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "pm_kw_list = []\n",
        "question_list.append(\"What is known about transmission, incubation, and environmental stability\")\n",
        "kw_list.append(\"2019-nCoV, COVID-19, coronavirus, person to person,touch,temperature, human to human, humidity, interpersonal contact,, transmission, shedding\")\n",
        "\n",
        "\n",
        "\n",
        "topic_area['What is known about transmission, incubation, and environmental stability?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "\n",
        "\n",
        "#1\n",
        "#What do we know about COVID-19 risk factors?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "\n",
        "question_list.append(\"What risk factors contribute to the severity of 2019-nCoV\")\n",
        "kw_list.append(\"2019-nCoV, COVID-19, coronavirus, novel coronavirus, susceptible, neonates, pregnant, socio-economic, behavioral, age, elderly, young, old, children\")\n",
        "\n",
        "\n",
        "topic_area['What do we know about COVID-19 risk factors?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "\n",
        "#2\n",
        "#What do we know about virus genetics, origin, and evolution?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "\n",
        "\n",
        "question_list.append(\"What animal did 2019-nCoV come from\")\n",
        "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, coronavirus, novel coronavirus, animals, zoonotic, farm, spillover, animal to human, bats, snakes, exotic animals\")\n",
        "\n",
        "\n",
        "topic_area['What do we know about virus genetics, origin, and evolution?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "#3\n",
        "#What do we know about vaccines and therapeutics?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "pm_kw_list = []\n",
        "question_list.append(\"What drugs or therapies or antiviral are being investigated and recommended\")\n",
        "kw_list.append(\"2019-nCoV,  COVID-19, coronavirus, novel coronavirus, drug, antiviral, testing, clinical trial, study\")\n",
        "\n",
        "\n",
        "topic_area['What do we know about vaccines and therapeutics?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "\n",
        "#4\n",
        "#What do we know about non-pharmaceutical interventions?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "question_list.append(\"Which non-pharmaceutical interventions limit tramsission\")\n",
        "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, non-pharmaceutical interventions, npi\")\n",
        "\n",
        "\n",
        "topic_area['What do we know about non-pharmaceutical interventions?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "#5\n",
        "#What has been published about medical care?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "\n",
        "\n",
        "question_list.append(\"What adjunctive or supportive methods can help patients\")\n",
        "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, adjunctive, supportive, extracorporeal membrane oxygenation, ecmo\")\n",
        "\n",
        "\n",
        "topic_area['What has been published about medical care?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "#6\n",
        "#What do we know about diagnostics and surveillance?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "question_list.append(\"What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV\")\n",
        "kw_list.append(\"2019-nCoV, SARS-CoV-2, COVID-19, coronavirus, novel coronavirus, diagnosis, tools, detetion, testing, throughput\")\n",
        "\n",
        "topic_area['What do we know about diagnostics and surveillance?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "\n",
        "\n",
        "#7\n",
        "#What has been published about information sharing and inter-sectoral collaboration?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "\n",
        "question_list.append('What collaborations are happening within the research community')\n",
        "kw_list.append('inter-sectorial, international, collaboration, global, coronavirus, novel coronavirus, sharing')\n",
        "\n",
        "\n",
        "topic_area['What has been published about information sharing and inter-sectoral collaboration?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "\n",
        "#8\n",
        "#What has been published about ethical and social science considerations?\n",
        "question_list = []\n",
        "kw_list = []\n",
        "\n",
        "\n",
        "question_list.append(\"What are the major ethical issues related pandemic outbreaks\")\n",
        "kw_list.append(\"ehtics, pandemic, caregivers, health care workers, social media\")\n",
        "\n",
        "\n",
        "topic_area['What has been published about ethical and social science considerations?'] = list(zip(question_list,kw_list))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Gkj2vEhqKg",
        "colab_type": "code",
        "outputId": "4fe847d2-368a-4c20-bc7a-6fa3445c3a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "source": [
        "i = all_topics[0]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:02<00:02,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "28 48 -2.045008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "69 95 4.751896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What is known about transmission, incubation, and environmental stability</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with only Abstract\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Isolation and identification of human coronavirus 229E from frequently touched environmental surfaces of a university classroom that is cleaned daily</td>\n",
              "      <td>Tania Bonny</td>\n",
              "      <td><div> our findings reinforce the notion that contact transmission may be possible for this virus <font color='red'>cov-229e is relatively stable in the environment. our findings reinforce the notion that contact transmission may be possible for this virus.</font> </div></td>\n",
              "      <td>0.637799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>First known person-to-person transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in the USA</td>\n",
              "      <td>Isaac Ghinai</td>\n",
              "      <td><div> contacts were people with  <font color='red'>exposure to a patient with covid-19 on or after the patient ' s symptom onset date</font> .</div></td>\n",
              "      <td>0.341198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (5675 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "268 278 3.5963469\n",
            "7 15 -6.0997705\n",
            "443 448 -0.6629781\n",
            "81 88 -1.4098103\n",
            "2 47 -11.257873\n",
            "183 197 -0.683667\n",
            "129 130 -4.745346\n",
            "173 176 -0.2543293\n",
            "3 3 -5.820122\n",
            "117 124 -5.118868\n",
            "69 222 1.0908566\n",
            "89 373 -2.0283432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 1/2 [01:28<01:28, 88.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "43 55 -0.37333322\n",
            "69 79 2.3101263\n",
            "378 389 3.9716048\n",
            "304 305 -4.9994955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [01:55<00:00, 57.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "370 391 4.4934115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What is known about transmission, incubation, and environmental stability</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with full paper\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First known person-to-person transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in the USA</td>\n",
              "      <td>Isaac Ghinai</td>\n",
              "      <td><div> we declare no competing interests <font color='red'>substantial knowledge gaps remain regarding the transmissibility between humans</font> </div></td>\n",
              "      <td>0.513984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Isolation and identification of human coronavirus 229E from frequently touched environmental surfaces of a university classroom that is cleaned daily</td>\n",
              "      <td>Tania Bonny</td>\n",
              "      <td><div>  <font color='red'>cov-229e can remain infectious on environmental surfaces, and potentially poses a biohazard by contact transmission</font> </div></td>\n",
              "      <td>0.361994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrWYjRThqKk",
        "colab_type": "code",
        "outputId": "8df7c592-d077-4812-ab48-76a0928de469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "source": [
        "i = all_topics[1]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fbbaff75fb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mDisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-00085e0a48ea>\u001b[0m in \u001b[0;36mDisplay_all\u001b[0;34m(query, keywords, abst)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#get database by ourselves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 1 column 162520129 (char 162520128)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klTTFjdbhqKw",
        "colab_type": "code",
        "outputId": "1c35f9f6-5e44-409b-acd9-a343016eecd1",
        "colab": {}
      },
      "source": [
        "i = all_topics[2]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:05,  1.09s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:01<00:03,  1.01it/s]\u001b[A\n",
            " 50%|█████     | 3/6 [00:02<00:02,  1.29it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:05<00:03,  1.67s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:07<00:01,  1.72s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What animal did 2019-nCoV come from</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with only Abstract\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Outbreak 2019-nCoV (Wuhan virus), a novel Coronavirus: human-to-human transmission, travel-related cases, and vaccine readiness</td>\n",
              "      <td>Robyn Ralph</td>\n",
              "      <td><div> with a seemingly comparable chain of events as the origin of sars-cov, the initial infections with 2019-ncov appears to be linked to contact with animals in  <font color='red'>wet markets</font> .</div></td>\n",
              "      <td>0.423477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Consensus statement The species Severe acute respiratory syndrome- related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2 Coronaviridae Study Group of the International Committee on Taxonomy of Viruses*</td>\n",
              "      <td>Info missed</td>\n",
              "      <td><div> based on phylogeny, taxonomy and established practice, the csg recognizes this virus as forming a sister clade to the prototype human and  <font color='red'>bat</font>  severe acute respiratory syndrome corona -</div></td>\n",
              "      <td>0.380103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>Ping Liu</td>\n",
              "      <td><div>the outbreak of 2019-ncov pneumonia in the city of wuhan, china has resulted in more than 70,000 laboratory confirmed cases, and recent studies showed that 2019-ncov (sars-cov-2) could be of  <font color='red'>bat</font>  origin but involve other potential intermediate hosts.</div></td>\n",
              "      <td>0.327245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Emerging novel coronavirus (2019-nCoV)-current scenario, evolutionary perspective based on genome analysis and recent developments</td>\n",
              "      <td>Yashpal Singh Malik</td>\n",
              "      <td><div>coronaviruses are the well-known cause of severe respiratory, enteric and systemic infections in a wide range of hosts including man,  <font color='red'>mammals, fish, and avian</font> .</div></td>\n",
              "      <td>0.280161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding</td>\n",
              "      <td>Roujian Lu</td>\n",
              "      <td><div> as of jan 26,2020, more than 2000 cases of 2019-ncov infection have been confirmed, most of which involved people living in or visiting wuhan, and  <font color='red'>human</font> -to-</div></td>\n",
              "      <td>0.142267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3822 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 12%|█▎        | 1/8 [00:20<02:20, 20.01s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6509 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 25%|██▌       | 2/8 [00:54<02:25, 24.24s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6860 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 38%|███▊      | 3/8 [01:30<02:19, 27.83s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (4428 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 50%|█████     | 4/8 [01:53<01:45, 26.40s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7531 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 62%|██████▎   | 5/8 [02:32<01:30, 30.32s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (15394 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 75%|███████▌  | 6/8 [03:53<01:30, 45.45s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3295 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 88%|████████▊ | 7/8 [04:11<00:37, 37.04s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6109 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "100%|██████████| 8/8 [04:43<00:00, 35.39s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What animal did 2019-nCoV come from</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with full paper\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>Ping Liu</td>\n",
              "      <td><div> / 2020 <font color='red'>malayan pangolins</font> </div></td>\n",
              "      <td>0.567853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RNA based mNGS approach identifies a novel human coronavirus from two individual pneumonia cases in 2019 Wuhan outbreak</td>\n",
              "      <td>Liangjun Chen</td>\n",
              "      <td><div> <font color='red'>bats</font> </div></td>\n",
              "      <td>0.386718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Outbreak 2019-nCoV (Wuhan virus), a novel Coronavirus: human-to-human transmission, travel-related cases, and vaccine readiness</td>\n",
              "      <td>Robyn Ralph</td>\n",
              "      <td><div> 1), were obtained from  <font color='red'>genbank</font> .</div></td>\n",
              "      <td>0.324047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Genomic characterisation and epidemiology of 2019 novel coronavirus: implications for virus origins and receptor binding</td>\n",
              "      <td>Roujian Lu</td>\n",
              "      <td><div> therefore, on the basis of current data, it seems likely that the 2019-ncov causing the wuhan outbreak might also be initially hosted by  <font color='red'>bats</font> , and might have been transmitted to humans via currently unknown wild animal (s) sold at the huanan seafood market.</div></td>\n",
              "      <td>0.307604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emerging novel coronavirus (2019-nCoV)-current scenario, evolutionary perspective based on genome analysis and recent developments</td>\n",
              "      <td>Yashpal Singh Malik</td>\n",
              "      <td><div>  <font color='red'>bats</font>  are considered as the natural reservoir hosts and play a crucial role in transmitting various viruses, including ebola, nipah, coronavirus and others (cui et al.</div></td>\n",
              "      <td>0.284420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Consensus statement The species Severe acute respiratory syndrome- related coronavirus: classifying 2019-nCoV and naming it SARS-CoV-2 Coronaviridae Study Group of the International Committee on Taxonomy of Viruses*</td>\n",
              "      <td>Info missed</td>\n",
              "      <td><div> <font color='red'>human coronavirus 3</font> </div></td>\n",
              "      <td>0.281045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The deadly coronaviruses: The 2003 SARS pandemic and the 2020 novel coronavirus epidemic in China</td>\n",
              "      <td>Yongshi Yang</td>\n",
              "      <td><div> <font color='red'>civets</font> </div></td>\n",
              "      <td>0.207842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>COVID-19: Epidemiology, Evolution, and Cross-Disciplinary Perspectives Trends in Molecular Medicine</td>\n",
              "      <td>Jiumeng Sun</td>\n",
              "      <td><div> xx 11 <font color='red'>bats</font> </div></td>\n",
              "      <td>0.194110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWDoGHCehqK1",
        "colab_type": "code",
        "outputId": "f53b3d9c-91f4-4c0e-a66c-fe37e2aaf291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "i = all_topics[3]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b17c0db5c4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_topics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7q5nJn6hqK7",
        "colab_type": "code",
        "outputId": "4334a585-dbba-4bce-ab88-72c47d14a8ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "i = all_topics[4]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ee6761c5a7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDisplay_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_topics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaleIcSchqLB",
        "colab_type": "code",
        "outputId": "df2ae5d5-299c-4642-9fc7-0d446f7542d9",
        "colab": {}
      },
      "source": [
        "i = all_topics[5]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:01<00:03,  1.06it/s]\u001b[A\n",
            " 50%|█████     | 3/6 [00:02<00:02,  1.21it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:05<00:02,  1.46s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:06<00:01,  1.42s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What adjunctive or supportive methods can help patients</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with only Abstract\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Emergent severe acute respiratory distress syndrome caused by adenovirus type 55 in immunocompetent adults in 2013: a prospective observational study</td>\n",
              "      <td>Bing Sun</td>\n",
              "      <td><div> the clinical features and outcomes of the most critically ill patients with severe acute respiratory distress syndrome (ards) caused by hadv-55 requiring  <font color='red'>invasive mechanical ventilation (imv) and / or extracorporeal membrane oxygenation</font>  (ecmo) are lacking.</div></td>\n",
              "      <td>0.521152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Intravenous vitamin C as adjunctive therapy for enterovirus/rhinovirus induced acute respiratory distress syndrome</td>\n",
              "      <td>Alpha Fowler</td>\n",
              "      <td><div> this report outlines the first use of high dose intravenous vitamin c as an  <font color='red'>interventional therapy</font>  for ards, resulting from enterovirus / rhinovirus respiratory infection.</div></td>\n",
              "      <td>0.458741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Extracorporeal membrane oxygenation for severe Middle East respiratory syndrome coronavirus</td>\n",
              "      <td>Mohammed Alshahrani</td>\n",
              "      <td><div> the objective of this study is to compare the outcomes of mers-cov patients before and after the availability of  <font color='red'>extracorporeal membrane oxygenation</font>  (ecmo) as a rescue therapy in severely hypoxemic patients who failed conventional strategies.</div></td>\n",
              "      <td>0.450459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mobile ECMO team for inter-hospital transportation of patients with ARDS: a retrospective case series</td>\n",
              "      <td>Alberto Lucchini</td>\n",
              "      <td><div> 29 patients (69 %) were transported with  <font color='red'>extracorporeal membrane oxygenation support</font> , while 13 patients (31 %) were transported with conventional ventilation.</div></td>\n",
              "      <td>0.324622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Application of extracorporeal membrane oxygenation in patients with severe acute respiratory distress syndrome induced by avian influenza A (H7N9) viral pneumonia: national data from the Chinese multicentre collaboration</td>\n",
              "      <td>Linna Huang</td>\n",
              "      <td><div> 05) after 48 h on  <font color='red'>ecmo support</font> .</div></td>\n",
              "      <td>0.315255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (5968 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 14%|█▍        | 1/7 [00:31<03:07, 31.27s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3546 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 29%|██▊       | 2/7 [00:49<02:17, 27.43s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3129 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 43%|████▎     | 3/7 [01:05<01:36, 24.06s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3535 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 57%|█████▋    | 4/7 [01:24<01:07, 22.34s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (5176 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 71%|███████▏  | 5/7 [01:51<00:47, 23.78s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3055 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 86%|████████▌ | 6/7 [02:07<00:21, 21.41s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3335 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "100%|██████████| 7/7 [02:24<00:00, 20.67s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What adjunctive or supportive methods can help patients</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with full paper\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Extracorporeal membrane oxygenation for severe Middle East respiratory syndrome coronavirus</td>\n",
              "      <td>Mohammed Alshahrani</td>\n",
              "      <td><div> <font color='red'>adjunctive therapies</font> </div></td>\n",
              "      <td>0.644751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Extracorporeal membrane oxygenation with prone position ventilation successfully rescues infantile pertussis: a case report and literature review</td>\n",
              "      <td>Jingyi Shi</td>\n",
              "      <td><div> <font color='red'>lung protective strategies and a restrictive fluid strategy</font> </div></td>\n",
              "      <td>0.449246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emergent severe acute respiratory distress syndrome caused by adenovirus type 55 in immunocompetent adults in 2013: a prospective observational study</td>\n",
              "      <td>Bing Sun</td>\n",
              "      <td><div> <font color='red'>invasive mechanical ventilation and / or extracorporeal membrane oxygenation (ecmo)</font> </div></td>\n",
              "      <td>0.447816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mobile ECMO team for inter-hospital transportation of patients with ARDS: a retrospective case series</td>\n",
              "      <td>Alberto Lucchini</td>\n",
              "      <td><div> <font color='red'>extracorporeal respiratory support</font> </div></td>\n",
              "      <td>0.430143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Planning and provision of ECMO services for severe ARDS during the COVID-19 pandemic and other outbreaks of emerging infectious diseases Health-care Development</td>\n",
              "      <td>( Hospital</td>\n",
              "      <td><div> <font color='red'>extracorporeal membrane oxygenation</font> </div></td>\n",
              "      <td>0.364851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Application of extracorporeal membrane oxygenation in patients with severe acute respiratory distress syndrome induced by avian influenza A (H7N9) viral pneumonia: national data from the Chinese multicentre collaboration</td>\n",
              "      <td>Linna Huang</td>\n",
              "      <td><div> 05) after  <font color='red'>ecmo support</font> .</div></td>\n",
              "      <td>0.276846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FELK-PJhqLF",
        "colab_type": "code",
        "outputId": "b3c93df5-fc15-411f-e1d0-a04d75800eca",
        "colab": {}
      },
      "source": [
        "i = all_topics[6]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:01<00:08,  1.75s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:02<00:06,  1.58s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:05<00:05,  1.74s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:06<00:03,  1.62s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:08<00:01,  1.64s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:09<00:00,  1.56s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with only Abstract\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review</td>\n",
              "      <td>Junxiong Pang</td>\n",
              "      <td><div> however,  <font color='red'>serological assays as well as point-of-care testing kits</font>  have not been developed but are likely in the near future.</div></td>\n",
              "      <td>0.566219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Potential T-cell and B-cell Epitopes of 2019-nCoV</td>\n",
              "      <td>Ethan Fast</td>\n",
              "      <td><div> here we use  <font color='red'>computational tools from structural biology and machine learning</font>  to identify 2019-ncov t-cell and b-cell epitopes based on viral protein antigen presentation and antibody binding properties.</div></td>\n",
              "      <td>0.539724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Title: Genome Detective Coronavirus Typing Tool for rapid identification and characterization of novel coronavirus genomes Short title: Automated tool for phylogenetic and mutational analysis of coronaviruses genomes</td>\n",
              "      <td>Sara Cleemput</td>\n",
              "      <td><div> the tool also allows tracking of new viral mutations as the outbreak expands globally, which may help to accelerate the development of  <font color='red'>novel diagnostics, drugs and vaccines</font> .</div></td>\n",
              "      <td>0.518947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Genome Detective Coronavirus Typing Tool for rapid identification and characterization of novel coronavirus genomes</td>\n",
              "      <td>Sara Cleemput</td>\n",
              "      <td><div> the tool also allows tracking of new viral mutations as the outbreak expands globally, which may help to accelerate the development of  <font color='red'>novel diagnostics, drugs and vaccines</font>  to stop the covid-19 disease.</div></td>\n",
              "      <td>0.507591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rapid colorimetric detection of COVID-19 coronavirus using a reverse tran- scriptional loop-mediated isothermal amplification (RT-LAMP) diagnostic plat- form: iLACO</td>\n",
              "      <td>Lin Yu</td>\n",
              "      <td><div> the accuracy, simplicity and versatility of the new developed method suggests that  <font color='red'>ilaco assays can be conveniently applied with for 2019-ncov threat control, even in those cases where specialized molecular biology equipment is not available</font> .</div></td>\n",
              "      <td>0.481790</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3393 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 17%|█▋        | 1/6 [00:18<01:31, 18.20s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (2579 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 33%|███▎      | 2/6 [00:31<01:07, 16.85s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (1986 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 50%|█████     | 3/6 [00:42<00:44, 14.99s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (2062 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 67%|██████▋   | 4/6 [00:53<00:27, 13.81s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7473 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 83%|████████▎ | 5/6 [01:34<00:21, 21.88s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (2106 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "100%|██████████| 6/6 [01:45<00:00, 17.59s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with full paper\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Potential Rapid Diagnostics, Vaccine and Therapeutics for 2019 Novel Coronavirus (2019-nCoV): A Systematic Review</td>\n",
              "      <td>Junxiong Pang</td>\n",
              "      <td><div> com / xxx / s1, table s1 : example of full search strategy in pubmed, table s2 : google search : 2019-ncov diagnostics, table s3 : summary of diagnostic assays developed for 2019-ncov, table s4 <font color='red'>rapid diagnostics, vaccines and therapeutics</font> </div></td>\n",
              "      <td>0.494263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eak4f0DrhqLQ",
        "colab_type": "code",
        "outputId": "a36d2161-a364-4512-99a0-870c5ff097b3",
        "colab": {}
      },
      "source": [
        "i = all_topics[7]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:02<00:13,  2.18s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:04<00:10,  2.08s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:05<00:07,  1.80s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [00:07<00:05,  1.94s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [00:10<00:04,  2.18s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [00:11<00:01,  1.82s/it]\u001b[A\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.76s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What collaborations are happening within the research community</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with only Abstract\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C-ME: A 3D Community-Based, Real-Time Collaboration Tool for Scientific Research and Training</td>\n",
              "      <td>A Kolatkar</td>\n",
              "      <td><div>the need for effective collaboration tools is growing as  <font color='red'>multidisciplinary proteome-wide projects and distributed research teams become more common</font> .</div></td>\n",
              "      <td>0.681837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R E V I E W partnership: experiences of co-learning and supporting the healthcare system in Uganda</td>\n",
              "      <td>Open Access</td>\n",
              "      <td><div>  <font color='red'>training and research are a key focus of the partnership and have involved both staff and students of both institutions including guest lectures, seminars and conference presentations</font> .</div></td>\n",
              "      <td>0.592211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emerging respiratory tract infections 2 Emerging infectious diseases and pandemic potential: status quo and reducing risk of global spread</td>\n",
              "      <td>Brian Mccloskey</td>\n",
              "      <td><div>  <font color='red'>collaboration between countries should be encouraged in a way that acknowledges the benefi ts that derive from sharing biological material and establishing equitable collaborative research partnerships</font> .</div></td>\n",
              "      <td>0.588500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fogarty International Center collaborative networks in infectious disease modeling: Lessons learnt in research and capacity building</td>\n",
              "      <td>Martha Nelson</td>\n",
              "      <td><div> <font color='red'>due to a combination of ecological, political, and demographic factors, the emergence of novel pathogens has been increasingly observed in animals and humans in recent decades. enhancing global capacity to study and interpret infectious disease surveillance data, and to develop data-driven computational models to guide policy, represents one of the most cost-effective, and yet overlooked, ways to prepare for the next pandemic. epidemiological and behavioral data from recent pandemics and historic scourges have provided rich opportunities for validation of computational models, while new sequencing technologies and the ' big data ' revolution present new tools for studying the epidemiology of outbreaks in real time. for the past two decades, the division of international epidemiology and population studies (dieps) of the nih fogarty international center has spearheaded two synergistic programs to better understand and devise control strategies for global infectious disease threats. the multinational influenza seasonal mortality study (misms) has strengthened global capacity to study the epidemiology and evolutionary dynamics of influenza viruses in 80 countries by organizing international research activities and training workshops. the research and policy in infectious disease dynamics (rapidd) program and its precursor activities has established a network of global experts in infectious disease modeling operating at the research-policy interface, with collaborators in 78 countries. these activities have provided evidence-based recommendations for disease control, including during large-scale outbreaks of pandemic influenza, ebola and zika virus. together, these programs have coordinated international collaborative networks</font>  to advance the study of emerging disease threats and the field of computational epidemic modeling.</div></td>\n",
              "      <td>0.533397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A global bibliometric analysis of Plesiomonas- related research (1990 -2017)</td>\n",
              "      <td>Temitope Ekundayoid</td>\n",
              "      <td><div> here, we carried out a bibliometric survey that aimed to examine publication trends in plesiomonas-related research by time and place,  <font color='red'>international collaborative works</font> , identify gaps and suggest directions for future research.</div></td>\n",
              "      <td>0.502882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (9063 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 11%|█         | 1/9 [00:47<06:21, 47.63s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3995 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 22%|██▏       | 2/9 [01:08<04:37, 39.60s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (5146 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 33%|███▎      | 3/9 [01:35<03:34, 35.78s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (5780 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 44%|████▍     | 4/9 [02:05<02:50, 34.18s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (3170 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 56%|█████▌    | 5/9 [02:22<01:56, 29.03s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7117 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 67%|██████▋   | 6/9 [03:01<01:35, 31.78s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6362 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 78%|███████▊  | 7/9 [03:34<01:04, 32.41s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6534 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 89%|████████▉ | 8/9 [04:09<00:32, 32.99s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6728 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "100%|██████████| 9/9 [04:45<00:00, 31.68s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What collaborations are happening within the research community</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with full paper\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fogarty International Center collaborative networks in infectious disease modeling: Lessons learnt in research and capacity building</td>\n",
              "      <td>Martha Nelson</td>\n",
              "      <td><div> <font color='red'>establishing strong international collaborative research networks</font> </div></td>\n",
              "      <td>0.668296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C-ME: A 3D Community-Based, Real-Time Collaboration Tool for Scientific Research and Training</td>\n",
              "      <td>A Kolatkar</td>\n",
              "      <td><div> 82 mb swf) <font color='red'>research teams are increasingly interdisciplinary and collaborative among laboratories in different departments and institutions located around the world</font> </div></td>\n",
              "      <td>0.593848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_00uFcLkhqLV",
        "colab_type": "code",
        "outputId": "505c1f95-c91f-4573-822e-65a394e096ac",
        "colab": {}
      },
      "source": [
        "i = all_topics[8]\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = True)\n",
        "Display_all(topic_area[i][0][0], topic_area[i][0][1], abst = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:08,  1.03it/s]\u001b[A\n",
            " 20%|██        | 2/10 [00:02<00:09,  1.16s/it]\u001b[A\n",
            " 30%|███       | 3/10 [00:04<00:09,  1.37s/it]\u001b[A\n",
            " 40%|████      | 4/10 [00:05<00:07,  1.30s/it]\u001b[A\n",
            " 50%|█████     | 5/10 [00:06<00:05,  1.12s/it]\u001b[A\n",
            " 60%|██████    | 6/10 [00:06<00:03,  1.00it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:07<00:02,  1.17it/s]\u001b[A\n",
            " 80%|████████  | 8/10 [00:09<00:02,  1.11s/it]\u001b[A\n",
            " 90%|█████████ | 9/10 [00:10<00:01,  1.20s/it]\u001b[A\n",
            "100%|██████████| 10/10 [00:12<00:00,  1.25s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What are the major ethical issues related pandemic outbreaks</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with only Abstract\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ethics for pandemics beyond influenza: Ebola, drug- resistant tuberculosis, and anticipating future ethical challenges in pandemic preparedness and response</td>\n",
              "      <td>Maxwell Smith</td>\n",
              "      <td><div> <font color='red'>the unprecedented outbreak of ebola virus disease (evd) in west africa has raised several novel ethical issues for global outbreak preparedness. it has also illustrated that familiar ethical issues in infectious disease management endure despite considerable efforts to understand and mitigate such issues in the wake of past outbreaks. to improve future global outbreak preparedness and response, we must examine these shortcomings and reflect upon the current state of ethical preparedness. to this end, we focus our efforts in this article on the examination of one substantial area : ethical guidance in pandemic plans. we argue that, due in part to their focus on considerations arising specifically in relation to pandemics of influenza origin, pandemic plans and their existing ethical guidance are ill-equipped to anticipate and facilitate the navigation of unique ethical challenges that may arise in other infectious disease pandemics. we proceed by outlining three reasons why this is so, and situate our analysis in the context of the evd outbreak and the threat posed by drug-resistant tuberculosis : (1) different infectious diseases have distinct characteristics that challenge anticipated or existing modes of pandemic prevention, preparedness, response, and recovery</font> , (2) clear, transparent, context-specific ethical reasoning and justification within current influenza pandemic plans are lacking, and (3) current plans neglect the context of how other significant pandemics may manifest.</div></td>\n",
              "      <td>0.710840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Risk Management and Healthcare Policy Dovepress Critical role of ethics in clinical management and public health response to the West Africa Ebola epidemic</td>\n",
              "      <td>Morenike Folayan</td>\n",
              "      <td><div> ethical issues related to prevention and containment include the  <font color='red'>appropriateness and scope of quarantine and isolation within and outside affected countries</font> .</div></td>\n",
              "      <td>0.689570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Special Issue Pandethics</td>\n",
              "      <td>M Selgelid</td>\n",
              "      <td><div>this paper explains the ethical importance of infectious diseases, and reviews four major ethical issues associated with pandemic influenza :  <font color='red'>the obligation of individuals to avoid infecting others, healthcare workers ' ' duty to treat ', allocation of scarce resources, and coercive social distancing measures</font> .</div></td>\n",
              "      <td>0.659091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The prospect of pandemic influenza: Why should the optometrist be concerned about a public health problem?</td>\n",
              "      <td>Gregory Hom</td>\n",
              "      <td><div> the  <font color='red'>ethical and legal issues surrounding control of a pandemic influenza</font>  and the prospect of telemedicine as a form of social distancing are also discussed.</div></td>\n",
              "      <td>0.639385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BMC Medical Ethics On pandemics and the duty to care: whose duty? who cares?</td>\n",
              "      <td>Carly Ruderman</td>\n",
              "      <td><div> despite this challenge,  <font color='red'>professional codes of ethics are silent on the issue of duty to care during communicable disease outbreaks</font> , thus providing no guidance on what is expected of hcps or how they ought to approach their duty to care in the face of risk.</div></td>\n",
              "      <td>0.615739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>653-662 Lor et al</td>\n",
              "      <td>Aun Lor</td>\n",
              "      <td><div> methods : we reviewed the meeting reports, notes and stories and mapped outcomes to the key ethical challenges for pandemic influenza response described in the world health organization ' s (who ' s) guidance, ethical considerations in developing a public health response to pandemic influenza :  <font color='red'>transparency and public engagement, allocation of resources, social distancing, obligations to and of healthcare workers, and international collaboration</font> .</div></td>\n",
              "      <td>0.605742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The duty to care in an influenza pandemic: A qualitative study of Canadian public perspectives</td>\n",
              "      <td>Cécile Bensimon</td>\n",
              "      <td><div> this study involved three townhall meetings held between february 2008 and may 2010 in three urban settings in canada in order to probe lay citizens ' views about ethical issues related to pandemic influenza, including  <font color='red'>issues surrounding the duty to care</font> .</div></td>\n",
              "      <td>0.492084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Fight or Flight: The Ethics of Emergency Physician Disaster Response</td>\n",
              "      <td>Kenneth Iserson</td>\n",
              "      <td><div> however, we need to ask :  <font color='red'>should they, and will they, work rather than flee</font>  ?</div></td>\n",
              "      <td>0.278741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (4292 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 10%|█         | 1/10 [00:22<03:21, 22.44s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6534 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 20%|██        | 2/10 [00:56<03:27, 25.96s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7944 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 30%|███       | 3/10 [01:39<03:37, 31.01s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (11056 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 40%|████      | 4/10 [02:38<03:57, 39.53s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (6189 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 50%|█████     | 5/10 [03:12<03:08, 37.68s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (4853 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 60%|██████    | 6/10 [03:37<02:16, 34.04s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7145 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 70%|███████   | 7/10 [04:15<01:45, 35.18s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7046 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 80%|████████  | 8/10 [04:52<01:11, 35.73s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (7998 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            " 90%|█████████ | 9/10 [05:34<00:37, 37.71s/it]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (5671 > 512). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "100%|██████████| 10/10 [06:04<00:00, 36.46s/it]\u001b[A\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"font-family: Times New Roman; font-size: 28px; padding-bottom:28px\"><b>Query</b>: What are the major ethical issues related pandemic outbreaks</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Search with full paper\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>BERT-SQuAD Answer with Highlights</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The prospect of pandemic influenza: Why should the optometrist be concerned about a public health problem?</td>\n",
              "      <td>Gregory Hom</td>\n",
              "      <td><div> <font color='red'>extreme measures that may be required to quickly control a deadly virus</font> </div></td>\n",
              "      <td>0.532387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ethics for pandemics beyond influenza: Ebola, drug- resistant tuberculosis, and anticipating future ethical challenges in pandemic preparedness and response</td>\n",
              "      <td>Maxwell Smith</td>\n",
              "      <td><div> <font color='red'>testing investigational agents in vaccine trials</font> </div></td>\n",
              "      <td>0.507242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Special Issue Pandethics</td>\n",
              "      <td>M Selgelid</td>\n",
              "      <td><div> <font color='red'>the obligation of individuals to avoid infecting others, healthcare workers ' ' duty to treat ', allocation of scarce resources, and the use of coercive social distancing measures</font> </div></td>\n",
              "      <td>0.487058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ethics-sensitivity of the Ghana national integrated strategic response plan for pandemic influenza</td>\n",
              "      <td>Amos Laar</td>\n",
              "      <td><div> <font color='red'>recurring tension in public health between the rights of individual liberties versus public health promotion</font> </div></td>\n",
              "      <td>0.431597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>653-662 Lor et al</td>\n",
              "      <td>Aun Lor</td>\n",
              "      <td><div> <font color='red'>low literacy level, poverty, and trust of and / or deference to health authorities</font> </div></td>\n",
              "      <td>0.405956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Risk Management and Healthcare Policy Dovepress Critical role of ethics in clinical management and public health response to the West Africa Ebola epidemic</td>\n",
              "      <td>Morenike Folayan</td>\n",
              "      <td><div> the authors report no conflicts of interest in this work <font color='red'>informed consent</font> </div></td>\n",
              "      <td>0.278898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BMC Medical Ethics On pandemics and the duty to care: whose duty? who cares?</td>\n",
              "      <td>Carly Ruderman</td>\n",
              "      <td><div> <font color='red'>physicians ' duty to care</font> </div></td>\n",
              "      <td>0.276583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Fight or Flight: The Ethics of Emergency Physician Disaster Response</td>\n",
              "      <td>Kenneth Iserson</td>\n",
              "      <td><div> <font color='red'>professional ethical statements about expected conduct establish important professional expectations and norms</font> </div></td>\n",
              "      <td>0.275383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The duty to care in an influenza pandemic: A qualitative study of Canadian public perspectives</td>\n",
              "      <td>Cécile Bensimon</td>\n",
              "      <td><div> <font color='red'>issues surrounding the duty to care</font> </div></td>\n",
              "      <td>0.208956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Pandémie grippale A/H5N1 et niveau de préparation du Niger : une étude sur les connaissances des soignants et l'organisation générale des soins Preparedness for influenza A/H5N1 pandemic in Niger: a study on health care workers' knowledge and global organization of health activities</td>\n",
              "      <td>E D&apos;</td>\n",
              "      <td><div> <font color='red'>differences economiques et sanitaires sont essentielles, puisque plus encore qu ' auparavant, a l ' heure de la mondialisation, les pathogenes se jouent des frontieres</font> </div></td>\n",
              "      <td>0.139903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTGyQql2hqLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}